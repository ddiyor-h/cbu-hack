# Подготовка данных для обучения модели прогнозирования дефолтов

## Обзор

Данный документ описывает все трансформации данных, выполненные для подготовки датасета к обучению моделей машинного обучения для прогнозирования кредитных дефолтов.

**Дата:** 2025-11-15
**Исходный датасет:** `/home/dr/cbu/final_dataset_imputed.parquet`
**Целевая метрика:** AUC (Area Under ROC Curve)

---

## Характеристики исходного датасета

- **Размер:** 89,999 строк × 62 столбца
- **Пропущенные значения:** 0 (данные уже очищены и импутированы)
- **Целевая переменная:** `default` (бинарная: 0 = нет дефолта, 1 = дефолт)
- **Дисбаланс классов:** 5.10% дефолтов (соотношение 1:18.6)

### Распределение классов

| Класс | Количество | Процент |
|-------|-----------|---------|
| Нет дефолта (0) | 85,405 | 94.9% |
| Дефолт (1) | 4,594 | 5.1% |

---

## Этап 1: Инженерия признаков

Создано **16 новых признаков** на основе доменных знаний кредитного скоринга:

### Финансовые коэффициенты

1. **total_debt_to_income** - Отношение общего долга к годовому доходу
   - Формула: `total_debt_amount / (annual_income + 1)`
   - Показывает общую долговую нагрузку относительно дохода

2. **revolving_to_income** - Отношение возобновляемого баланса к доходу
   - Формула: `revolving_balance / (annual_income + 1)`
   - Измеряет использование кредитных карт относительно дохода

3. **payment_burden** - Нагрузка по платежам
   - Формула: `monthly_payment / (monthly_income + 1)`
   - Доля месячного дохода, идущая на новый платеж по кредиту

4. **debt_service_coverage** - Коэффициент покрытия долга
   - Формула: `monthly_income / (existing_monthly_debt + monthly_payment + 1)`
   - Способность покрывать все долговые обязательства

5. **income_vs_regional** - Доход относительно региональной медианы
   - Формула: `annual_income / (regional_median_income + 1)`
   - Экономическое положение заемщика в регионе

6. **income_per_dependent** - Доход на иждивенца
   - Формула: `annual_income / (num_dependents + 1)`
   - Финансовая нагрузка с учетом семьи

### Поведенческие метрики

7. **logins_per_year** - Активность входов в систему
   - Формула: `num_login_sessions / account_age`
   - Вовлеченность клиента в онлайн-банкинг

8. **service_calls_per_year** - Обращения в службу поддержки
   - Формула: `num_customer_service_calls / account_age`
   - Может указывать на проблемы или активное управление счетом

9. **account_age_years** - Возраст аккаунта в годах
   - Формула: `2025 - account_open_year`
   - История взаимоотношений с банком

### Кредитные показатели

10. **available_credit_after_loan** - Доступный кредит после займа
    - Формула: `available_credit - loan_amount`
    - Остаточная кредитная способность

11. **credit_capacity** - Общая кредитная емкость
    - Формула: `available_credit + revolving_balance`
    - Полный кредитный лимит клиента

12. **combined_risk_score** - Комбинированный показатель риска
    - Формула: `debt_to_income_ratio * 0.4 + credit_utilization * 0.4 + (num_customer_service_calls / 10) * 0.2`
    - Простая эвристика общего риска

### Категориальные признаки (биннинг)

13. **credit_util_category** - Категория использования кредита
    - Низкое: < 30%
    - Среднее: 30-60%
    - Высокое: > 60%

14. **age_group** - Возрастная группа
    - 18-25, 26-35, 36-45, 46-55, 55+

15. **employment_stability** - Стабильность занятости
    - Новая (< 1 года)
    - Короткая (1-3 года)
    - Средняя (3-5 лет)
    - Долгая (> 5 лет)

16. **application_time_of_day** - Время подачи заявки
    - Ночь (0-6), Утро (6-12), День (12-18), Вечер (18-24)

---

## Этап 2: Разделение на обучающую и тестовую выборки

**Стратегия:** Стратифицированное разделение для сохранения распределения классов

### Параметры

- **Размер тестовой выборки:** 20% (17,999 записей)
- **Размер обучающей выборки:** 80% (72,000 записей)
- **Random state:** 42 (для воспроизводимости)
- **Стратификация:** По целевой переменной `default`

### Проверка баланса классов

| Выборка | Размер | Процент дефолтов |
|---------|--------|------------------|
| Обучающая | 72,000 | 5.11% |
| Тестовая | 17,999 | 5.10% |
| Исходная | 89,999 | 5.10% |

**Результат:** Стратификация успешна, баланс классов сохранен

---

## Этап 3: Кодирование категориальных признаков

После инженерии признаков в датасете осталось **18 категориальных признаков**. Применены две стратегии кодирования в зависимости от кардинальности:

### One-Hot Encoding (11 признаков с низкой кардинальностью)

Применен к признакам с менее чем 10 уникальными значениями:

1. **preferred_contact** (3 значения)
2. **account_status_code** (5 значений)
3. **employment_type** (9 значений)
4. **education** (5 значений)
5. **marital_status** (3 значения)
6. **origination_channel** (4 значения)
7. **credit_util_category** (3 значения)
8. **age_group** (5 значений)
9. **employment_stability** (4 значения)
10. **application_time_of_day** (4 значения)

**Результат:** Создано **42 бинарных признака** (drop_first=True для избежания мультиколлинеарности)

### Frequency Encoding (7 признаков с высокой кардинальностью)

Применен к признакам с 10 и более уникальными значениями:

1. **referral_code** (7,805 значений) → `referral_code_freq`
2. **credit_usage_amount** (82,354 значений) → `credit_usage_amount_freq`
3. **total_monthly_debt_payment** (85,634 значений) → `total_monthly_debt_payment_freq`
4. **monthly_free_cash_flow** (88,109 значений) → `monthly_free_cash_flow_freq`
5. **loan_type** (12 значений) → `loan_type_freq`
6. **marketing_campaign** (26 значений) → `marketing_campaign_freq`
7. **state** (20 значений) → `state_freq`

**Метод:** Частота категории рассчитана на обучающей выборке, применена к обеим выборкам. Неизвестные категории в тесте кодируются как 0.

**Важно:** Все кодировщики обучены только на тренировочных данных для предотвращения утечки данных.

---

## Этап 4: Масштабирование признаков

Применена **стандартизация (StandardScaler)** для линейных моделей:

- **Формула:** `(x - mean) / std`
- **Обучение:** Только на тренировочных данных
- **Применение:** К обеим выборкам
- **Количество признаков:** 108

### Сохранены две версии

1. **Немасштабированная** (`X_train.parquet`, `X_test.parquet`)
   - Для древовидных моделей: Random Forest, XGBoost, LightGBM, CatBoost
   - Деревья инвариантны к масштабу признаков

2. **Масштабированная** (`X_train_scaled.parquet`, `X_test_scaled.parquet`)
   - Для линейных моделей: Logistic Regression, Ridge, Lasso
   - Для нейронных сетей
   - Улучшает сходимость градиентных методов

---

## Итоговая структура данных

### Размеры датасетов

| Файл | Размер | Описание |
|------|--------|----------|
| X_train.parquet | 72,000 × 108 | Обучающие признаки (немасштабированные) |
| X_test.parquet | 17,999 × 108 | Тестовые признаки (немасштабированные) |
| X_train_scaled.parquet | 72,000 × 108 | Обучающие признаки (масштабированные) |
| X_test_scaled.parquet | 17,999 × 108 | Тестовые признаки (масштабированные) |
| y_train.parquet | 72,000 × 1 | Целевая переменная (обучение) |
| y_test.parquet | 17,999 × 1 | Целевая переменная (тест) |

### Состав признаков (108 итоговых)

- **Исходные числовые:** 43
- **Исходные бинарные:** 4
- **Созданные числовые:** 10
- **One-Hot закодированные:** 42
- **Frequency закодированные:** 7
- **Созданные категориальные (биннинг):** 4 (преобразованы в one-hot)

---

## Рекомендации по работе с дисбалансом классов

Датасет имеет сильный дисбаланс (5.1% дефолтов). Рекомендуемые подходы:

### 1. Взвешивание классов

Рекомендуемые веса (рассчитаны на основе обучающей выборки):

```python
class_weights = {
    0: 0.5269,  # Нет дефолта
    1: 9.7953   # Дефолт
}
```

Применение в scikit-learn:
```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(class_weight={0: 0.5269, 1: 9.7953})
# или просто:
model = RandomForestClassifier(class_weight='balanced')
```

### 2. SMOTE (Synthetic Minority Over-sampling Technique)

```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
```

**Внимание:** SMOTE следует применять только после разделения на train/test.

### 3. Настройка порога классификации

Вместо стандартного порога 0.5 оптимизировать на основе ROC-кривой:
- Использовать `predict_proba()` для получения вероятностей
- Выбрать порог, максимизирующий метрику (например, F1-score или точку Юдена)

---

## Метаданные и воспроизводимость

Сохранены следующие файлы для обеспечения воспроизводимости:

### 1. feature_names.txt
Список всех 108 итоговых признаков в правильном порядке.

### 2. preprocessing_metadata.json
Содержит:
- Параметры разделения (random_state=42, test_size=0.2)
- Список созданных признаков
- Метаданные кодирования (one-hot колонки, частотные кодировщики)
- Параметры масштабирования (средние и стандартные отклонения)
- Размеры выборок и распределение классов

### 3. class_balance_info.json
Содержит:
- Количество образцов в каждой выборке
- Количество дефолтов/не-дефолтов
- Рекомендуемые веса классов
- Соотношение классов

---

## Следующие шаги: Обучение модели

### Рекомендуемая последовательность

1. **Базовые модели (бенчмарк)**
   ```python
   # Logistic Regression (использовать масштабированные данные)
   # Random Forest (использовать немасштабированные данные)
   # XGBoost (использовать немасштабированные данные)
   ```

2. **Метрики оценки**
   - **Основная:** AUC (Area Under ROC Curve)
   - Дополнительно: Precision, Recall, F1-Score, PR-AUC

3. **Кросс-валидация**
   - Стратифицированная K-Fold (k=5 или k=10)
   - Обеспечивает надежную оценку производительности

4. **Работа с дисбалансом**
   - Начать с `class_weight='balanced'`
   - Экспериментировать с SMOTE
   - Оптимизировать порог классификации

5. **Настройка гиперпараметров**
   - GridSearchCV или RandomizedSearchCV
   - Оптимизация по AUC

6. **Анализ важности признаков**
   - Feature importances для древовидных моделей
   - SHAP values для интерпретируемости
   - Удаление неинформативных признаков

---

## Проверка качества данных

### Чек-лист перед обучением

- [x] Нет пропущенных значений
- [x] Нет категориальных признаков (все закодированы)
- [x] Баланс классов сохранен в train/test
- [x] Кодировщики обучены только на train (нет утечки данных)
- [x] Масштабирование выполнено на основе train
- [x] Все преобразования документированы
- [x] Random seed установлен (42)
- [x] Целевая переменная имеет правильный тип (int64)

### Потенциальные проблемы

1. **Высокая кардинальность frequency-encoded признаков**
   - Некоторые признаки имеют очень много уникальных значений
   - Frequency encoding может не полностью захватить информацию
   - Рассмотреть target encoding или embeddings

2. **Дисбаланс классов**
   - 5.1% дефолтов - сильный дисбаланс
   - Обязательно использовать class_weight или SMOTE
   - Оценивать по AUC, а не по accuracy

3. **Мультиколлинеарность**
   - Созданные финансовые коэффициенты могут коррелировать
   - Проверить корреляционную матрицу
   - При необходимости удалить высококоррелированные признаки

---

## Пример кода для загрузки данных

```python
import pandas as pd

# Для древовидных моделей
X_train = pd.read_parquet('/home/dr/cbu/X_train.parquet')
X_test = pd.read_parquet('/home/dr/cbu/X_test.parquet')

# Для линейных моделей
X_train_scaled = pd.read_parquet('/home/dr/cbu/X_train_scaled.parquet')
X_test_scaled = pd.read_parquet('/home/dr/cbu/X_test_scaled.parquet')

# Целевая переменная
y_train = pd.read_parquet('/home/dr/cbu/y_train.parquet')['default']
y_test = pd.read_parquet('/home/dr/cbu/y_test.parquet')['default']

# Загрузка метаданных
import json
with open('/home/dr/cbu/preprocessing_metadata.json', 'r') as f:
    metadata = json.load(f)

with open('/home/dr/cbu/class_balance_info.json', 'r') as f:
    class_info = json.load(f)

print(f"Количество признаков: {len(metadata['feature_names'])}")
print(f"Рекомендуемые веса классов: {class_info['recommended_class_weights']}")
```

---

## Контакты и дополнительная информация

**Дата подготовки:** 2025-11-15
**Автор:** Data Science Team
**Версия:** 1.0

Для вопросов или уточнений обращайтесь к документации проекта.
