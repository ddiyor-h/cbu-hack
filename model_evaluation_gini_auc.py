"""
–û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
–ú–µ—Ç—Ä–∏–∫–∏: GINI –∏ AUC

GINI –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç - –≤–∞–∂–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –≤ –∫—Ä–µ–¥–∏—Ç–Ω–æ–º —Å–∫–æ—Ä–∏–Ω–≥–µ:
- GINI = 2 * AUC - 1
- –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç 0 (—Å–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å) –¥–æ 1 (–∏–¥–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)
- GINI > 0.4 —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤ –∫—Ä–µ–¥–∏—Ç–Ω–æ–º —Å–∫–æ—Ä–∏–Ω–≥–µ
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import (
    roc_auc_score,
    roc_curve,
    precision_recall_curve,
    confusion_matrix,
    classification_report,
    average_precision_score
)
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 100)
print("–û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –ü–ï–†–í–û–ô –ò–¢–ï–†–ê–¶–ò–ò - –ú–ï–¢–†–ò–ö–ò GINI –ò AUC")
print("=" * 100)

# ============================================================================
# 1. –ó–ê–ì–†–£–ó–ö–ê –û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò –ò –î–ê–ù–ù–´–•
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò –ò –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•")
print("=" * 100)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é XGBoost –º–æ–¥–µ–ª—å
model = xgb.Booster()
model.load_model('/home/dr/cbu/xgboost_model_v1.json')
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: xgboost_model_v1.json")

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
X_test = pd.read_parquet('/home/dr/cbu/X_test.parquet')
y_test = pd.read_parquet('/home/dr/cbu/y_test.parquet')['default'].values

print(f"‚úÖ X_test –∑–∞–≥—Ä—É–∂–µ–Ω: {X_test.shape}")
print(f"‚úÖ y_test –∑–∞–≥—Ä—É–∂–µ–Ω: {len(y_test)} –∑–∞–ø–∏—Å–µ–π")
print(f"   - –ö–ª–∞—Å—Å 0 (–Ω–µ—Ç –¥–µ—Ñ–æ–ª—Ç–∞): {(y_test == 0).sum():,} ({(y_test == 0).sum() / len(y_test) * 100:.2f}%)")
print(f"   - –ö–ª–∞—Å—Å 1 (–¥–µ—Ñ–æ–ª—Ç):      {(y_test == 1).sum():,} ({(y_test == 1).sum() / len(y_test) * 100:.2f}%)")

# ============================================================================
# 2. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ú–û–î–ï–õ–ò
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô")
print("=" * 100)

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DMatrix –¥–ª—è XGBoost
dtest = xgb.DMatrix(X_test)

# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 1 (–¥–µ—Ñ–æ–ª—Ç)
y_pred_proba = model.predict(dtest)
print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
print(f"   - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {y_pred_proba.min():.6f}")
print(f"   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {y_pred_proba.max():.6f}")
print(f"   - –°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:     {y_pred_proba.mean():.6f}")
print(f"   - –ú–µ–¥–∏–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:   {np.median(y_pred_proba):.6f}")

# –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ø–æ—Ä–æ–≥ 0.5)
y_pred_binary = (y_pred_proba >= 0.5).astype(int)

# ============================================================================
# 3. –†–ê–°–ß–ï–¢ –û–°–ù–û–í–ù–´–• –ú–ï–¢–†–ò–ö: AUC –ò GINI
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 3: –†–ê–°–ß–ï–¢ –ú–ï–¢–†–ò–ö AUC –ò GINI")
print("=" * 100)

# –†–∞—Å—á–µ—Ç AUC (Area Under ROC Curve)
auc_score = roc_auc_score(y_test, y_pred_proba)

# –†–∞—Å—á–µ—Ç GINI –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞
gini_score = 2 * auc_score - 1

print("\n" + "üéØ " + "=" * 96)
print("–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ú–û–î–ï–õ–ò")
print("=" * 100)
print(f"\nüìä AUC (Area Under ROC Curve):  {auc_score:.6f}")
print(f"üìä GINI –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç:             {gini_score:.6f}")
print(f"\nüí° –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è GINI:")
print(f"   - GINI = 0:     –ú–æ–¥–µ–ª—å –Ω–µ –ª—É—á—à–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —É–≥–∞–¥—ã–≤–∞–Ω–∏—è")
print(f"   - GINI = 0.3:   –ü—Ä–∏–µ–º–ª–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
print(f"   - GINI = 0.4:   –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞")
print(f"   - GINI = 0.5+:  –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
print(f"   - GINI = 1.0:   –ò–¥–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (—Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏)")

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
if gini_score < 0.3:
    quality = "‚ùå –ù–ò–ó–ö–û–ï –ö–ê–ß–ï–°–¢–í–û - —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ"
elif gini_score < 0.4:
    quality = "‚ö†Ô∏è  –ü–†–ò–ï–ú–õ–ï–ú–û–ï –ö–ê–ß–ï–°–¢–í–û - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å"
elif gini_score < 0.5:
    quality = "‚úÖ –•–û–†–û–®–ï–ï –ö–ê–ß–ï–°–¢–í–û"
elif gini_score < 0.6:
    quality = "‚úÖ‚úÖ –û–ß–ï–ù–¨ –•–û–†–û–®–ï–ï –ö–ê–ß–ï–°–¢–í–û"
else:
    quality = "üèÜ –û–¢–õ–ò–ß–ù–û–ï –ö–ê–ß–ï–°–¢–í–û"

print(f"\nüéØ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {quality}")
print("=" * 100)

# ============================================================================
# 4. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 4: –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê")
print("=" * 100)

# Average Precision Score (–¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤)
avg_precision = average_precision_score(y_test, y_pred_proba)
print(f"\nüìä Average Precision Score: {avg_precision:.6f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_binary)
print("\nüìä Confusion Matrix (–ø–æ—Ä–æ–≥ = 0.5):")
print(f"   True Negatives (TN):  {cm[0, 0]:,}")
print(f"   False Positives (FP): {cm[0, 1]:,}")
print(f"   False Negatives (FN): {cm[1, 0]:,}")
print(f"   True Positives (TP):  {cm[1, 1]:,}")

# –ú–µ—Ç—Ä–∏–∫–∏ –∏–∑ Confusion Matrix
tn, fp, fn, tp = cm.ravel()
sensitivity = tp / (tp + fn)  # Recall, True Positive Rate
specificity = tn / (tn + fp)  # True Negative Rate
precision = tp / (tp + fp) if (tp + fp) > 0 else 0
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0

print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ—Ä–æ–≥ = 0.5):")
print(f"   Sensitivity (Recall):  {sensitivity:.4f}  - –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–æ–≤")
print(f"   Specificity:           {specificity:.4f}  - –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–µ–¥–µ—Ñ–æ–ª—Ç–æ–≤")
print(f"   Precision:             {precision:.4f}  - —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–µ—Ñ–æ–ª—Ç–∞")
print(f"   F1-Score:              {f1_score:.4f}  - –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ Precision –∏ Recall")

# Classification Report
print("\nüìä –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
print(classification_report(y_test, y_pred_binary, target_names=['–ù–µ—Ç –¥–µ—Ñ–æ–ª—Ç–∞', '–î–µ—Ñ–æ–ª—Ç']))

# ============================================================================
# 5. –ü–û–ò–°–ö –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ì–û –ü–û–†–û–ì–ê
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 5: –ê–ù–ê–õ–ò–ó –ü–û–†–û–ì–û–í –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
print("=" * 100)

# –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
thresholds_to_test = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤:")
print(f"{'–ü–æ—Ä–æ–≥':>6} | {'Precision':>10} | {'Recall':>10} | {'F1-Score':>10} | {'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –¥–µ—Ñ–æ–ª—Ç–æ–≤':>20}")
print("-" * 70)

for threshold in thresholds_to_test:
    y_pred_thresh = (y_pred_proba >= threshold).astype(int)
    cm_thresh = confusion_matrix(y_test, y_pred_thresh)
    tn_t, fp_t, fn_t, tp_t = cm_thresh.ravel()

    precision_t = tp_t / (tp_t + fp_t) if (tp_t + fp_t) > 0 else 0
    recall_t = tp_t / (tp_t + fn_t)
    f1_t = 2 * (precision_t * recall_t) / (precision_t + recall_t) if (precision_t + recall_t) > 0 else 0

    predicted_defaults = (y_pred_proba >= threshold).sum()

    print(f"{threshold:>6.1f} | {precision_t:>10.4f} | {recall_t:>10.4f} | {f1_t:>10.4f} | {predicted_defaults:>20,}")

# ============================================================================
# 6. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 6: –°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô")
print("=" * 100)

# –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å 6 –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
fig = plt.figure(figsize=(20, 12))

# 1. ROC –∫—Ä–∏–≤–∞—è
ax1 = plt.subplot(2, 3, 1)
fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'AUC = {auc_score:.4f}\nGINI = {gini_score:.4f}')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Model (AUC=0.5)')
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend(loc='lower right', fontsize=11)
plt.grid(True, alpha=0.3)

# 2. Precision-Recall –∫—Ä–∏–≤–∞—è
ax2 = plt.subplot(2, 3, 2)
precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)
plt.plot(recall_curve, precision_curve, linewidth=2, label=f'Avg Precision = {avg_precision:.4f}')
plt.xlabel('Recall', fontsize=12)
plt.ylabel('Precision', fontsize=12)
plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')
plt.legend(loc='upper right', fontsize=11)
plt.grid(True, alpha=0.3)

# 3. Confusion Matrix
ax3 = plt.subplot(2, 3, 3)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: –ù–ï–¢ –¥–µ—Ñ–æ–ª—Ç–∞', '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: –î–ï–§–û–õ–¢'],
            yticklabels=['–§–∞–∫—Ç: –ù–ï–¢ –¥–µ—Ñ–æ–ª—Ç–∞', '–§–∞–∫—Ç: –î–ï–§–û–õ–¢'],
            annot_kws={'size': 14})
plt.title('Confusion Matrix (–ø–æ—Ä–æ–≥ = 0.5)', fontsize=14, fontweight='bold')
plt.ylabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å', fontsize=12)
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å', fontsize=12)

# 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
ax4 = plt.subplot(2, 3, 4)
plt.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.6, label='–ö–ª–∞—Å—Å 0 (–Ω–µ—Ç –¥–µ—Ñ–æ–ª—Ç–∞)', color='green', edgecolor='black')
plt.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.6, label='–ö–ª–∞—Å—Å 1 (–¥–µ—Ñ–æ–ª—Ç)', color='red', edgecolor='black')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–∞', fontsize=12)
plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=12)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π', fontsize=14, fontweight='bold')
plt.legend(loc='upper right', fontsize=11)
plt.grid(True, alpha=0.3, axis='y')

# 5. F1-Score vs Threshold
ax5 = plt.subplot(2, 3, 5)
f1_scores = []
precision_scores = []
recall_scores = []
threshold_range = np.linspace(0.01, 0.99, 100)

for thresh in threshold_range:
    y_pred_t = (y_pred_proba >= thresh).astype(int)
    cm_t = confusion_matrix(y_test, y_pred_t)
    tn_t, fp_t, fn_t, tp_t = cm_t.ravel()

    prec_t = tp_t / (tp_t + fp_t) if (tp_t + fp_t) > 0 else 0
    rec_t = tp_t / (tp_t + fn_t) if (tp_t + fn_t) > 0 else 0
    f1_t = 2 * (prec_t * rec_t) / (prec_t + rec_t) if (prec_t + rec_t) > 0 else 0

    f1_scores.append(f1_t)
    precision_scores.append(prec_t)
    recall_scores.append(rec_t)

plt.plot(threshold_range, f1_scores, linewidth=2, label='F1-Score', color='blue')
plt.plot(threshold_range, precision_scores, linewidth=2, label='Precision', color='green', alpha=0.7)
plt.plot(threshold_range, recall_scores, linewidth=2, label='Recall', color='orange', alpha=0.7)
plt.xlabel('–ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏', fontsize=12)
plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏', fontsize=12)
plt.title('–ú–µ—Ç—Ä–∏–∫–∏ vs –ü–æ—Ä–æ–≥', fontsize=14, fontweight='bold')
plt.legend(loc='best', fontsize=11)
plt.grid(True, alpha=0.3)

# –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –ø–æ F1
optimal_threshold_idx = np.argmax(f1_scores)
optimal_threshold = threshold_range[optimal_threshold_idx]
optimal_f1 = f1_scores[optimal_threshold_idx]
plt.axvline(optimal_threshold, color='red', linestyle='--', linewidth=2,
            label=f'–û–ø—Ç–∏–º—É–º F1={optimal_f1:.3f} –ø—Ä–∏ {optimal_threshold:.3f}')
plt.legend(loc='best', fontsize=10)

# 6. –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ (—Ç–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
ax6 = plt.subplot(2, 3, 6)
ax6.axis('off')

metrics_text = f"""
–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ú–û–î–ï–õ–ò
{'=' * 40}

AUC Score:           {auc_score:.6f}
GINI Coefficient:    {gini_score:.6f}
Avg Precision:       {avg_precision:.6f}

–ö–ê–ß–ï–°–¢–í–û: {quality}

{'=' * 40}
–ú–ï–¢–†–ò–ö–ò –ü–†–ò –ü–û–†–û–ì–ï 0.5:

Sensitivity (Recall): {sensitivity:.4f}
Specificity:          {specificity:.4f}
Precision:            {precision:.4f}
F1-Score:             {f1_score:.4f}

{'=' * 40}
–û–ü–¢–ò–ú–ê–õ–¨–ù–´–ô –ü–û–†–û–ì (–ø–æ F1):

–ü–æ—Ä–æ–≥:     {optimal_threshold:.4f}
F1-Score:  {optimal_f1:.4f}

{'=' * 40}
CONFUSION MATRIX (–ø–æ—Ä–æ–≥=0.5):

True Negatives:   {cm[0,0]:>6,}
False Positives:  {cm[0,1]:>6,}
False Negatives:  {cm[1,0]:>6,}
True Positives:   {cm[1,1]:>6,}
"""

ax6.text(0.1, 0.9, metrics_text, transform=ax6.transAxes,
         fontsize=11, verticalalignment='top', fontfamily='monospace',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

plt.tight_layout()
plt.savefig('/home/dr/cbu/model_evaluation_gini_auc.png', dpi=150, bbox_inches='tight')
print("‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: model_evaluation_gini_auc.png")

# ============================================================================
# 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ============================================================================

print("\n" + "=" * 100)
print("–®–ê–ì 7: –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
print("=" * 100)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV
results_df = pd.DataFrame({
    'customer_ref': X_test.index if hasattr(X_test, 'index') else range(len(X_test)),
    'actual': y_test,
    'predicted_proba': y_pred_proba,
    'predicted_class_05': y_pred_binary,
    'predicted_class_optimal': (y_pred_proba >= optimal_threshold).astype(int)
})
results_df.to_csv('/home/dr/cbu/model_predictions_with_gini.csv', index=False)
print("‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: model_predictions_with_gini.csv")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫
metrics_summary = pd.DataFrame({
    'Metric': ['AUC', 'GINI', 'Average_Precision', 'Sensitivity', 'Specificity',
               'Precision', 'F1_Score', 'Optimal_Threshold', 'Optimal_F1'],
    'Value': [auc_score, gini_score, avg_precision, sensitivity, specificity,
              precision, f1_score, optimal_threshold, optimal_f1]
})
metrics_summary.to_csv('/home/dr/cbu/model_metrics_summary.csv', index=False)
print("‚úÖ –°–≤–æ–¥–∫–∞ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: model_metrics_summary.csv")

# ============================================================================
# –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê
# ============================================================================

print("\n" + "=" * 100)
print("–§–ò–ù–ê–õ–¨–ù–ê–Ø –°–í–û–î–ö–ê –û–¶–ï–ù–ö–ò –ú–û–î–ï–õ–ò")
print("=" * 100)
print(f"\nüéØ AUC:  {auc_score:.6f}")
print(f"üéØ GINI: {gini_score:.6f}")
print(f"\nüí° –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç {quality}")
print(f"\nüìÅ –§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
print(f"   1. model_evaluation_gini_auc.png - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫")
print(f"   2. model_predictions_with_gini.csv - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
print(f"   3. model_metrics_summary.csv - —Å–≤–æ–¥–∫–∞ –º–µ—Ç—Ä–∏–∫")
print("\n" + "=" * 100)
print("‚úÖ –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –ó–ê–í–ï–†–®–ï–ù–ê")
print("=" * 100)
