# Анализ и обработка пропущенных значений
## Проект прогнозирования кредитного дефолта

---

## Исполнительное резюме

**Задача:** Определить оптимальную стратегию обработки 4,462 пропущенных значений в датасете кредитных заявок для максимизации качества модели предсказания дефолта (метрика: AUC).

**Основные выводы:**
- Пропуски обнаружены в 3 столбцах из 62 (4.96% всех значений)
- Пропуски носят случайный характер (MCAR) - не коррелируют значимо с целевой переменной
- **Рекомендация: ИМПУТАЦИЯ** вместо удаления строк
- Импутация сохраняет 4,393 записи (4.88% датасета) для обучения модели
- Баланс классов полностью сохранен (5.10% дефолтов)

---

## 1. Обзор проблемы

### 1.1 Датасет

- **Размер:** 89,999 клиентов × 62 признака
- **Целевая переменная:** `default` (бинарная: 0/1)
- **Доля дефолтов:** 5.10% (дисбаланс классов 1:18.6)
- **Метрика качества:** AUC (Area Under ROC Curve)

### 1.2 Пропущенные значения

| Столбец | Пропущено | Процент | Тип данных | Источник |
|---------|-----------|---------|------------|----------|
| `employment_length` | 2,253 | 2.50% | Числовой (годы) | demographics.csv |
| `revolving_balance` | 1,377 | 1.53% | Числовой ($) | financial_ratios.jsonl |
| `num_delinquencies_2yrs` | 832 | 0.92% | Числовой (счетчик) | credit_history.parquet |
| **ВСЕГО** | **4,462** | **4.96%** | - | - |

### 1.3 Паттерны пропусков

Анализ совместного распределения показал, что пропуски **не коррелируют** между столбцами:

- `employment_length` × `revolving_balance`: только 35 записей с обоими пропусками (0.04%)
- `employment_length` × `num_delinquencies_2yrs`: только 22 записи (0.02%)
- `revolving_balance` × `num_delinquencies_2yrs`: только 12 записей (0.01%)

**Вывод:** Пропуски независимы, систематическая ошибка отсутствует.

---

## 2. Детальный анализ каждого столбца

### 2.1 `employment_length` (стаж работы)

#### Статистика

| Метрика | Значение |
|---------|----------|
| Пропущено | 2,253 (2.50%) |
| Минимум | 0.0 лет |
| Q1 (25%) | 3.0 лет |
| **Медиана (50%)** | **5.2 лет** |
| Среднее | 5.51 лет |
| Q3 (75%) | 7.7 лет |
| Максимум | 23.9 лет |
| Стандартное отклонение | 3.27 лет |
| Асимметрия (skewness) | 0.53 (правосторонняя) |
| Нулевых значений | 289 (0.33%) |
| Выбросов (IQR) | 543 (0.62%) |

#### Связь с целевой переменной

- **Доля дефолтов при пропуске:** 4.93%
- **Доля дефолтов при наличии:** 5.11%
- **Разница:** -0.18 п.п. (незначимая)
- **Корреляция с default:** -0.0499 (слабая отрицательная)

**Интерпретация:** Пропуск не несет дополнительной информации о вероятности дефолта. Это случайный пропуск (MCAR).

#### Рекомендация

**Метод:** Импутация **медианой** (5.20 лет)

**Обоснование:**
1. Медиана устойчива к выбросам (есть значения до 23.9 лет)
2. Распределение асимметричное (skew=0.53) - медиана точнее среднего
3. Разница в доле дефолтов при пропуске незначима - пропуск не информативен
4. Простой и надежный метод
5. Сохраняет естественное распределение признака

---

### 2.2 `revolving_balance` (остаток по возобновляемому кредиту)

#### Статистика

| Метрика | Значение |
|---------|----------|
| Пропущено | 1,377 (1.53%) |
| Минимум | $804.30 |
| Q1 (25%) | $16,560 |
| **Медиана (50%)** | **$29,295** |
| Среднее | $39,561 |
| Q3 (75%) | $50,942 |
| Максимум | $442,616 |
| Стандартное отклонение | $34,766 |
| Асимметрия (skewness) | 2.44 (сильная правосторонняя) |
| Нулевых значений | 0 (0%) |
| Выбросов (IQR) | 4,942 (5.58%) |

#### Связь с целевой переменной

- **Доля дефолтов при пропуске:** 5.30%
- **Доля дефолтов при наличии:** 5.10%
- **Разница:** +0.20 п.п. (незначимая)
- **Корреляция с default:** -0.0768 (слабая отрицательная)

**Интерпретация:** Пропуск слабо коррелирует с дефолтом. Большой разброс значений и выбросы требуют устойчивого метода импутации.

#### Рекомендация

**Метод:** Импутация **медианой по группам `credit_score`** с fallback на общую медиану

**Обоснование:**
1. Остаток по кредиту сильно зависит от кредитного рейтинга клиента
2. Группировка по `credit_score` (298 уникальных значений) повысит точность импутации
3. Медиана устойчива к выбросам (их 5.58%)
4. Сильная асимметрия распределения (skew=2.44) делает медиану предпочтительнее среднего
5. Финансовая метрика - важна точность импутации для корректности расчетных коэффициентов

**Алгоритм:**
1. Для каждой группы `credit_score` вычислить медиану `revolving_balance`
2. Заполнить пропуски медианой группы
3. Если для редких значений `credit_score` медиана недоступна, использовать общую медиану ($29,295)

---

### 2.3 `num_delinquencies_2yrs` (количество просрочек за 2 года)

#### Статистика

| Метрика | Значение |
|---------|----------|
| Пропущено | 832 (0.92%) |
| Минимум | 0 |
| Q1 (25%) | 0 |
| **Медиана (50%)** | **0** |
| Среднее | 0.02 |
| Q3 (75%) | 0 |
| Максимум | 2 |
| Стандартное отклонение | 0.14 |
| Асимметрия (skewness) | 7.16 (экстремальная) |
| **Нулевых значений** | **87,458 (98.08%)** |
| Выбросов (IQR) | 1,709 (1.92%) |

#### Распределение значений

- **0 просрочек:** 87,458 клиентов (98.08%)
- **1 просрочка:** ~1,500 клиентов (1.68%)
- **2 просрочки:** ~209 клиентов (0.24%)

#### Связь с целевой переменной

- **Доля дефолтов при пропуске:** 4.57%
- **Доля дефолтов при наличии:** 5.11%
- **Разница:** -0.54 п.п. (слабо значимая)
- **Корреляция с default:** +0.0393 (слабая положительная)

**Интерпретация:** Клиенты с пропущенными данными имеют НИЖЕ риск дефолта. Это поддерживает гипотезу, что отсутствие записи = отсутствие просрочек.

#### Рекомендация

**Метод:** Импутация **нулем** (0)

**Обоснование:**
1. **Семантика данных:** Отсутствие записи о просрочках логично интерпретировать как отсутствие просрочек
2. **Эмпирическое распределение:** 98% значений равны 0 - это нормальное состояние
3. **Связь с таргетом:** Доля дефолтов при пропуске НИЖЕ (-0.54 п.п.), что согласуется с гипотезой "нет данных = нет просрочек"
4. **Консервативный подход:** Предполагаем лучший сценарий при отсутствии информации
5. **Природа данных:** Счетчик событий - отсутствие записи часто означает отсутствие события

**Альтернативы (не рекомендуются):**
- Медиана (0) - дает тот же результат
- Среднее (0.02) - нелогично для счетчика, искажает распределение
- Создание индикатора - избыточно при незначимой разнице

---

## 3. Сравнение стратегий

### 3.1 Оцениваемые подходы

1. **Удаление строк** (Listwise deletion)
2. **Импутация средним** (Mean imputation)
3. **Импутация медианой** (Median imputation)
4. **Импутация нулями** (Zero imputation)
5. **Индикаторный метод** (Indicator + Median)
6. **KNN-импутация** (k-Nearest Neighbors)
7. **Доменная импутация** (Domain-specific, рекомендованная)

### 3.2 Результаты анализа

#### Удаление строк

| Метрика | Значение |
|---------|----------|
| Исходных строк | 89,999 |
| Строк после удаления | 85,606 |
| **Потеря данных** | **4,393 (4.88%)** |
| Доля дефолтов | 5.11% |
| Баланс классов | Сохранен (изменение +0.01 п.п.) |

**Недостатки:**
- Потеря почти 5% обучающих данных
- Снижение статистической мощности модели
- Потенциальное снижение обобщающей способности
- Неэффективное использование собранных данных

#### Импутация (рекомендуемая стратегия)

| Метрика | Значение |
|---------|----------|
| Исходных строк | 89,999 |
| Строк после импутации | **89,999** |
| Потеря данных | **0 (0%)** |
| Доля дефолтов | 5.10% |
| Баланс классов | Полностью сохранен |
| Пропусков после импутации | **0** |

**Преимущества:**
- Сохранение всех 89,999 записей для обучения
- Больше данных = потенциально выше качество модели
- Баланс классов не нарушен
- Семантически корректная обработка каждого типа пропусков

---

## 4. Рекомендованная стратегия

### 4.1 Алгоритм импутации

```python
# 1. employment_length - медиана
df['employment_length'].fillna(5.20, inplace=True)

# 2. revolving_balance - медиана по группам credit_score
df['revolving_balance'] = df.groupby('credit_score')['revolving_balance'].transform(
    lambda x: x.fillna(x.median())
)
# Fallback для редких credit_score
df['revolving_balance'].fillna(29294.70, inplace=True)

# 3. num_delinquencies_2yrs - нули
df['num_delinquencies_2yrs'].fillna(0, inplace=True)
```

### 4.2 Обоснование выбора

| Столбец | Метод | Обоснование |
|---------|-------|-------------|
| `employment_length` | Медиана (5.20) | Устойчивость к выбросам, асимметричное распределение, пропуск не информативен |
| `revolving_balance` | Медиана по группам `credit_score` | Зависимость от рейтинга, высокая точность, устойчивость к выбросам |
| `num_delinquencies_2yrs` | Нули (0) | Семантика данных, 98% значений = 0, консервативный подход |

### 4.3 Преимущества подхода

1. **Максимизация данных:** Сохранены все 89,999 записей
2. **Семантическая корректность:** Каждый столбец обработан с учетом его природы
3. **Точность:** Группировка для финансовых метрик повышает точность
4. **Устойчивость:** Медиана защищает от влияния выбросов
5. **Простота:** Воспроизводимый, понятный алгоритм
6. **Баланс классов:** Полностью сохранен (5.10%)

---

## 5. Результаты импутации

### 5.1 Итоговая статистика

| Метрика | Значение |
|---------|----------|
| **Пропусков ДО импутации** | 4,462 |
| **Пропусков ПОСЛЕ импутации** | **0** |
| Размер датасета | 89,999 строк × 62 столбца |
| Доля дефолтов (исходная) | 5.10% |
| Доля дефолтов (после импутации) | 5.10% |
| Числовых признаков | 48 |
| Сохранено записей vs удаление | +4,393 (+5.13%) |

### 5.2 Сохраненные файлы

1. **CSV:** `/home/dr/cbu/final_dataset_imputed.csv`
   - Размер: 89,999 строк × 62 столбца
   - Формат: UTF-8 с BOM
   - Пропусков: 0

2. **Parquet:** `/home/dr/cbu/final_dataset_imputed.parquet`
   - Размер: оптимизированный бинарный формат
   - Сжатие: snappy
   - Рекомендуется для быстрой загрузки

---

## 6. Сравнение с альтернативами

### 6.1 Почему НЕ выбраны другие методы

#### 1. Удаление строк
- ❌ Потеря 4.88% данных
- ❌ Снижение статистической мощности
- ❌ Неэффективное использование ресурсов

#### 2. Импутация средним (для всех столбцов)
- ❌ Не устойчива к выбросам
- ❌ Искажает распределение при асимметрии
- ❌ Для `num_delinquencies_2yrs` дает нецелочисленные значения (0.02)

#### 3. Импутация медианой (простая, для всех)
- ⚠ Для `revolving_balance` теряет возможность учесть зависимость от `credit_score`
- ⚠ Для `num_delinquencies_2yrs` семантически менее корректна, чем нули

#### 4. KNN-импутация
- ❌ Вычислительно дорогая (89,999 × 62 признака)
- ❌ Требует масштабирования и обработки категориальных переменных
- ❌ Избыточно сложна для 4.96% пропусков
- ⚠ Выигрыш в качестве модели минимален при таком малом проценте пропусков

#### 5. Индикаторный метод (флаг пропуска + импутация)
- ⚠ Добавляет 3 дополнительных признака
- ⚠ Оправдан только если пропуск информативен (у нас разница <0.54 п.п.)
- ❌ Усложняет модель без значимого выигрыша

### 6.2 Потенциальное влияние на AUC

При малом проценте пропусков (4.96%) и их случайном характере (MCAR) **разница между качественными методами импутации будет минимальной** (ожидается <0.5% изменения AUC).

**Ключевые факторы выбора:**
1. **Простота и воспроизводимость** ✓
2. **Семантическая корректность** ✓
3. **Сохранение всех данных** ✓
4. **Вычислительная эффективность** ✓

---

## 7. Рекомендации для моделирования

### 7.1 Использование импутированных данных

1. **Загрузка данных:**
   ```python
   # Рекомендуется использовать Parquet для скорости
   import pandas as pd
   df = pd.read_parquet('/home/dr/cbu/final_dataset_imputed.parquet')

   # Проверка отсутствия пропусков
   assert df.isnull().sum().sum() == 0
   ```

2. **Разделение на train/test:**
   ```python
   from sklearn.model_selection import train_test_split

   X = df.drop(['default', 'customer_ref', 'application_id'], axis=1)
   y = df['default']

   X_train, X_test, y_train, y_test = train_test_split(
       X, y, test_size=0.2, random_state=42, stratify=y
   )
   ```

3. **Обработка категориальных признаков:**
   - One-Hot Encoding для признаков с низкой кардинальностью (<10 категорий)
   - Target Encoding или Frequency Encoding для высокой кардинальности
   - Пример: `state` (50 штатов), `loan_purpose`, `employment_type`

### 7.2 Feature Engineering

Импутированные признаки можно использовать для создания дополнительных:

```python
# Отношение стажа к возрасту
df['employment_to_age_ratio'] = df['employment_length'] / df['age']

# Доля revolving balance в общем кредитном лимите
df['revolving_utilization'] = df['revolving_balance'] / df['total_credit_limit']

# Флаг наличия просрочек
df['has_delinquencies'] = (df['num_delinquencies_2yrs'] > 0).astype(int)
```

### 7.3 Валидация качества импутации

Для проверки качества импутации рекомендуется:

1. **Сравнить распределения** до и после импутации:
   ```python
   # До импутации (из final_dataset_clean.csv)
   # После импутации (из final_dataset_imputed.parquet)
   # Убедиться, что основные квантили не изменились
   ```

2. **Обучить baseline модель** на обеих версиях датасета:
   - С удалением строк (85,606 записей)
   - С импутацией (89,999 записей)
   - Сравнить AUC на кросс-валидации

3. **Проанализировать важность признаков:**
   - Если импутированные признаки имеют высокую важность, это может указывать на успешную импутацию
   - Если важность низкая, это не критично (пропусков было мало)

---

## 8. Выводы

### 8.1 Ключевые результаты

1. **Характер пропусков:** MCAR (случайный), не коррелируют с целевой переменной
2. **Процент пропусков:** 4.96% - небольшой, но значимый для сохранения
3. **Выбранный метод:** Доменная импутация (медиана, медиана по группам, нули)
4. **Сохранено данных:** 100% (89,999 записей вместо 85,606 при удалении)
5. **Качество обработки:** 0 пропусков, баланс классов сохранен

### 8.2 Ожидаемое влияние на модель

- **Объем данных:** +5.13% записей для обучения
- **AUC:** Ожидается сохранение или незначительное улучшение (<0.5%)
- **Обобщающая способность:** Повышение за счет большего объема данных
- **Устойчивость:** Медиана защищает от влияния выбросов

### 8.3 Следующие шаги

1. ✅ Импутация завершена - использовать `final_dataset_imputed.parquet`
2. ⏭ Feature Engineering - создание дополнительных признаков
3. ⏭ Feature Selection - отбор наиболее значимых признаков
4. ⏭ Model Training - обучение моделей (Logistic Regression, Random Forest, XGBoost, etc.)
5. ⏭ Hyperparameter Tuning - оптимизация гиперпараметров
6. ⏭ Evaluation - оценка на тестовой выборке с метрикой AUC

---

## 9. Контрольный чеклист

- [x] Проанализированы все столбцы с пропусками
- [x] Исследована связь пропусков с целевой переменной
- [x] Выбрана оптимальная стратегия для каждого столбца
- [x] Применена импутация ко всем пропускам
- [x] Проверено отсутствие пропусков в итоговом датасете
- [x] Сохранен баланс классов (5.10%)
- [x] Сохранены итоговые файлы (CSV и Parquet)
- [x] Задокументирован процесс импутации
- [ ] Валидация качества импутации через baseline модель (опционально)

---

**Дата анализа:** 2025-11-15
**Автор:** Claude Code (Data Science Specialist)
**Проект:** Credit Default Prediction ML
**Датасет:** 89,999 клиентов × 62 признака
**Метрика оценки:** AUC (Area Under ROC Curve)

---

## Приложение: Технические детали

### A. Использованные библиотеки

```python
import pandas as pd      # 2.x (data manipulation)
import numpy as np       # 1.x (numerical operations)
import pyarrow          # Parquet support
```

### B. Воспроизводимость

Все операции детерминированные, не используют случайность. Воспроизводимость 100%.

### C. Файлы проекта

1. **Входные данные:**
   - `final_dataset_clean.csv` - очищенный датасет с пропусками

2. **Выходные данные:**
   - `final_dataset_imputed.csv` - датасет после импутации (CSV)
   - `final_dataset_imputed.parquet` - датасет после импутации (Parquet, рекомендуется)

3. **Аналитические скрипты:**
   - `imputation_analysis_simple.py` - полный анализ и импутация

4. **Документация:**
   - `MISSING_VALUES_ANALYSIS_RU.md` - данный отчет

---

**Конец отчета**
