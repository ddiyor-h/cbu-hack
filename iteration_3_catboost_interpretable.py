"""
–ò–¢–ï–†–ê–¶–ò–Ø 3: CatBoost —Å –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å—é (Quick Test)

Expected AUC: 0.81-0.83
–í—Ä–µ–º—è: 30-60 –º–∏–Ω—É—Ç
–¶–µ–ª—å: +0.010-0.025 AUC + –ø–æ–ª–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å

CatBoost –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- Ordered boosting (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç target leakage)
- Symmetric trees (–ª—É—á—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è)
- Auto class weights (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç imbalance)
- –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å (feature importance, SHAP)
- –ë—ã—Å—Ç—Ä—ã–π inference

–ò–ù–¢–ï–†–ü–†–ï–¢–ò–†–£–ï–ú–û–°–¢–¨:
- Feature importance (gain, split)
- SHAP values –¥–ª—è —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- Partial dependence plots
- Interaction analysis
"""

import numpy as np
import pandas as pd
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import time
import warnings
warnings.filterwarnings('ignore')

# Configuration
RANDOM_STATE = 42
N_FOLDS = 5

# Paths
DATA_DIR = '/home/dr/cbu'
X_TRAIN_PATH = f'{DATA_DIR}/X_train_engineered.parquet'
Y_TRAIN_PATH = f'{DATA_DIR}/y_train.parquet'
X_TEST_PATH = f'{DATA_DIR}/X_test_engineered.parquet'
Y_TEST_PATH = f'{DATA_DIR}/y_test.parquet'

print("="*100)
print("–ò–¢–ï–†–ê–¶–ò–Ø 3: CatBoost —Å –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å—é")
print("="*100)
print()

# ============================================================================
# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
# ============================================================================

print("[1/6] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
X_train = pd.read_parquet(X_TRAIN_PATH)
y_train = pd.read_parquet(Y_TRAIN_PATH).values.ravel()
X_test = pd.read_parquet(X_TEST_PATH)
y_test = pd.read_parquet(Y_TEST_PATH).values.ravel()

print(f"‚úÖ Training set: {X_train.shape}")
print(f"‚úÖ Test set: {X_test.shape}")
print(f"‚úÖ Class distribution: {np.sum(y_train==0):,} no-default / {np.sum(y_train==1):,} default")
print(f"   Imbalance ratio: {np.sum(y_train==0)/np.sum(y_train==1):.1f}:1")
print(f"   Default rate: {np.mean(y_train):.2%}")
print()

# ============================================================================
# 2. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø CATBOOST
# ============================================================================

print("[2/6] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CatBoost...")
print()

catboost_params = {
    'iterations': 1000,
    'learning_rate': 0.05,
    'depth': 8,
    'l2_leaf_reg': 5,
    'auto_class_weights': 'Balanced',  # –ö–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è imbalanced data
    'eval_metric': 'AUC',
    'random_seed': RANDOM_STATE,
    'verbose': 100,
    'early_stopping_rounds': 50,
    'thread_count': -1,
    'boosting_type': 'Ordered',  # Ordered boosting –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è target leakage
    'bootstrap_type': 'Bayesian',  # Bayesian bootstrap –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏
}

print("üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
for param, value in catboost_params.items():
    if param not in ['verbose', 'thread_count']:
        print(f"   ‚Ä¢ {param}: {value}")
print()

# ============================================================================
# 3. CROSS-VALIDATION
# ============================================================================

print("[3/6] Cross-Validation (5-fold)...")
print()

cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)
cv_scores = []
models = []
oof_predictions = np.zeros(len(X_train))

for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):
    print(f"  Fold {fold+1}/{N_FOLDS}:")
    start_time = time.time()

    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
    y_tr, y_val = y_train[train_idx], y_train[val_idx]

    # Create pools
    train_pool = Pool(X_tr, y_tr)
    val_pool = Pool(X_val, y_val)

    # Train model
    model = CatBoostClassifier(**catboost_params)
    model.fit(
        train_pool,
        eval_set=val_pool,
        use_best_model=True,
        verbose=False
    )

    # Evaluate
    y_pred = model.predict_proba(X_val)[:, 1]
    oof_predictions[val_idx] = y_pred
    auc = roc_auc_score(y_val, y_pred)
    cv_scores.append(auc)
    models.append(model)

    elapsed = time.time() - start_time
    print(f"    ‚úÖ AUC: {auc:.4f}, Best iteration: {model.best_iteration_}, Time: {elapsed:.1f}s")

print()
print(f"üìä Cross-Validation Results:")
print(f"   ‚Ä¢ Mean CV AUC:  {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}")
print(f"   ‚Ä¢ Min AUC:      {np.min(cv_scores):.4f}")
print(f"   ‚Ä¢ Max AUC:      {np.max(cv_scores):.4f}")
print(f"   ‚Ä¢ GINI:         {2*np.mean(cv_scores)-1:.4f}")

# OOF AUC
oof_auc = roc_auc_score(y_train, oof_predictions)
print(f"   ‚Ä¢ OOF AUC:      {oof_auc:.4f}")
print()

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline
baseline_auc = 0.8047
improvement = np.mean(cv_scores) - baseline_auc
improvement_pct = (improvement / baseline_auc) * 100

print(f"üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Baseline:")
print(f"   ‚Ä¢ Baseline XGBoost: AUC = {baseline_auc:.4f}, GINI = {2*baseline_auc-1:.4f}")
print(f"   ‚Ä¢ CatBoost:         AUC = {np.mean(cv_scores):.4f}, GINI = {2*np.mean(cv_scores)-1:.4f}")
print(f"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ:        {improvement:+.4f} AUC ({improvement_pct:+.2f}%)")
print()

# ============================================================================
# 4. –û–ë–£–ß–ï–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò
# ============================================================================

print("[4/6] –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º train set...")

final_model = CatBoostClassifier(**catboost_params)
final_model.fit(
    X_train, y_train,
    eval_set=Pool(X_test, y_test),
    verbose=100,
    use_best_model=True
)

print(f"\n‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: {final_model.best_iteration_} –∏—Ç–µ—Ä–∞—Ü–∏–π")
print()

# ============================================================================
# 5. –¢–ï–°–¢–û–í–ê–Ø –û–¶–ï–ù–ö–ê
# ============================================================================

print("[5/6] –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ...")

y_test_pred = final_model.predict_proba(X_test)[:, 1]
test_auc = roc_auc_score(y_test, y_test_pred)
test_gini = 2 * test_auc - 1

print(f"\nüìä Test Set Results:")
print(f"   ‚Ä¢ Test AUC:  {test_auc:.4f}")
print(f"   ‚Ä¢ Test GINI: {test_gini:.4f}")
print(f"   ‚Ä¢ CV vs Test: {np.mean(cv_scores) - test_auc:+.4f} (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è)")
print()

# ============================================================================
# 6. –ò–ù–¢–ï–†–ü–†–ï–¢–ò–†–£–ï–ú–û–°–¢–¨
# ============================================================================

print("[6/6] –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")
print()

# 6.1 Feature Importance
print("üìä Feature Importance...")

feature_importance = final_model.get_feature_importance(type='FeatureImportance')
feature_names = X_train.columns

importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º
importance_df.to_csv(f'{DATA_DIR}/catboost_feature_importance.csv', index=False)
print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: catboost_feature_importance.csv")

# –¢–æ–ø-20
print("\n   –¢–æ–ø-20 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for i, (idx, row) in enumerate(importance_df.head(20).iterrows(), 1):
    print(f"   {i:2d}. {row['feature']:50s}: {row['importance']:8.2f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

# –ì—Ä–∞—Ñ–∏–∫ 1: –¢–æ–ø-30 feature importance
top_30 = importance_df.head(30)
ax1.barh(range(len(top_30)), top_30['importance'].values, color='steelblue', alpha=0.7)
ax1.set_yticks(range(len(top_30)))
ax1.set_yticklabels(top_30['feature'], fontsize=9)
ax1.set_xlabel('Feature Importance', fontsize=12, fontweight='bold')
ax1.set_title('Top-30 Feature Importance (CatBoost)', fontsize=14, fontweight='bold', pad=15)
ax1.invert_yaxis()
ax1.grid(axis='x', alpha=0.3)

# –ì—Ä–∞—Ñ–∏–∫ 2: ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)
ax2.plot(fpr, tpr, 'b-', lw=2, label=f'CatBoost (AUC = {test_auc:.4f})')
ax2.plot([0, 1], [0, 1], 'r--', lw=2, label='Random (AUC = 0.5)')
ax2.fill_between(fpr, tpr, alpha=0.2, color='blue')

ax2.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')
ax2.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')
ax2.set_title(f'ROC Curve\nTest AUC = {test_auc:.4f}, GINI = {test_gini:.4f}',
              fontsize=14, fontweight='bold', pad=15)
ax2.legend(loc='lower right', fontsize=10)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{DATA_DIR}/catboost_interpretation.png', dpi=150, bbox_inches='tight')
print(f"   ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: catboost_interpretation.png")

# 6.2 SHAP Values (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω shap)
try:
    import shap
    print("\nüìä SHAP Values Analysis...")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º TreeExplainer –¥–ª—è CatBoost
    explainer = shap.TreeExplainer(final_model)

    # –í—ã—á–∏—Å–ª—è–µ–º SHAP values –¥–ª—è sample —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –±–µ—Ä–µ–º 1000 –∑–∞–ø–∏—Å–µ–π)
    sample_size = min(1000, len(X_test))
    X_sample = X_test.sample(n=sample_size, random_state=RANDOM_STATE)

    shap_values = explainer.shap_values(X_sample)

    # Summary plot
    plt.figure(figsize=(12, 10))
    shap.summary_plot(shap_values, X_sample, max_display=20, show=False)
    plt.tight_layout()
    plt.savefig(f'{DATA_DIR}/catboost_shap_summary.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   ‚úÖ SHAP summary plot —Å–æ—Ö—Ä–∞–Ω–µ–Ω: catboost_shap_summary.png")

    # Mean absolute SHAP values
    mean_shap = np.abs(shap_values).mean(axis=0)
    shap_importance_df = pd.DataFrame({
        'feature': feature_names,
        'mean_abs_shap': mean_shap
    }).sort_values('mean_abs_shap', ascending=False)

    shap_importance_df.to_csv(f'{DATA_DIR}/catboost_shap_importance.csv', index=False)
    print(f"   ‚úÖ SHAP importance —Å–æ—Ö—Ä–∞–Ω–µ–Ω: catboost_shap_importance.csv")

    print("\n   –¢–æ–ø-10 –ø–æ SHAP values:")
    for i, (idx, row) in enumerate(shap_importance_df.head(10).iterrows(), 1):
        print(f"   {i:2d}. {row['feature']:50s}: {row['mean_abs_shap']:8.4f}")

except ImportError:
    print("\n‚ö†Ô∏è  SHAP library –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install shap")
    print("   SHAP –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω, –Ω–æ –º–æ–¥–µ–ª—å –≤—Å—ë —Ä–∞–≤–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞ —á–µ—Ä–µ–∑ feature importance")

# 6.3 Prediction Analysis
print("\nüìä Prediction Distribution Analysis...")

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# –ì—Ä–∞—Ñ–∏–∫ 1: –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
ax1.hist(y_test_pred[y_test == 0], bins=50, alpha=0.6, label='No Default',
         color='green', edgecolor='black', linewidth=0.5)
ax1.hist(y_test_pred[y_test == 1], bins=50, alpha=0.6, label='Default',
         color='red', edgecolor='black', linewidth=0.5)

ax1.set_xlabel('Predicted Probability', fontsize=12, fontweight='bold')
ax1.set_ylabel('Frequency', fontsize=12, fontweight='bold')
ax1.set_title('Distribution of Predicted Probabilities by True Class',
              fontsize=14, fontweight='bold', pad=15)
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3, axis='y')

# –ì—Ä–∞—Ñ–∏–∫ 2: Cumulative distribution
sorted_preds_0 = np.sort(y_test_pred[y_test == 0])
sorted_preds_1 = np.sort(y_test_pred[y_test == 1])

ax2.plot(sorted_preds_0, np.linspace(0, 1, len(sorted_preds_0)),
         'g-', lw=2, label='No Default (CDF)', alpha=0.7)
ax2.plot(sorted_preds_1, np.linspace(0, 1, len(sorted_preds_1)),
         'r-', lw=2, label='Default (CDF)', alpha=0.7)

ax2.set_xlabel('Predicted Probability', fontsize=12, fontweight='bold')
ax2.set_ylabel('Cumulative Probability', fontsize=12, fontweight='bold')
ax2.set_title('Cumulative Distribution of Predictions',
              fontsize=14, fontweight='bold', pad=15)
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{DATA_DIR}/catboost_predictions_analysis.png', dpi=150, bbox_inches='tight')
print(f"   ‚úÖ Prediction analysis —Å–æ—Ö—Ä–∞–Ω–µ–Ω: catboost_predictions_analysis.png")

# ============================================================================
# 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ============================================================================

print("\n" + "="*100)
print("üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
print("="*100)
print()

# Predictions
predictions_df = pd.DataFrame({
    'prediction': y_test_pred,
    'true_label': y_test
})
predictions_df.to_csv(f'{DATA_DIR}/predictions_catboost_iter3.csv', index=False)
print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: predictions_catboost_iter3.csv")

# Model
final_model.save_model(f'{DATA_DIR}/model_catboost_iter3.cbm')
print(f"‚úÖ –ú–æ–¥–µ–ª—å: model_catboost_iter3.cbm")

# Summary
summary_df = pd.DataFrame({
    'Metric': [
        'CV AUC (mean)',
        'CV AUC (std)',
        'OOF AUC',
        'Test AUC',
        'Test GINI',
        'CV-Test Gap',
        'Baseline AUC',
        'Improvement',
        'Best Iteration'
    ],
    'Value': [
        f'{np.mean(cv_scores):.4f}',
        f'{np.std(cv_scores):.4f}',
        f'{oof_auc:.4f}',
        f'{test_auc:.4f}',
        f'{test_gini:.4f}',
        f'{np.mean(cv_scores) - test_auc:+.4f}',
        f'{baseline_auc:.4f}',
        f'{improvement:+.4f}',
        str(final_model.best_iteration_)
    ]
})

summary_df.to_csv(f'{DATA_DIR}/catboost_iter3_summary.csv', index=False)
print(f"‚úÖ Summary: catboost_iter3_summary.csv")

# ============================================================================
# 8. –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢
# ============================================================================

print("\n" + "="*100)
print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ - –ò–¢–ï–†–ê–¶–ò–Ø 3: CatBoost")
print("="*100)
print()

print("üéØ –û–°–ù–û–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
print(f"   ‚Ä¢ CV AUC:        {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}")
print(f"   ‚Ä¢ Test AUC:      {test_auc:.4f}")
print(f"   ‚Ä¢ Test GINI:     {test_gini:.4f}")
print(f"   ‚Ä¢ OOF AUC:       {oof_auc:.4f}")
print()

print("üìà –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE:")
print(f"   ‚Ä¢ Baseline:      AUC = {baseline_auc:.4f}")
print(f"   ‚Ä¢ CatBoost:      AUC = {np.mean(cv_scores):.4f}")
print(f"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ:     {improvement:+.4f} ({improvement_pct:+.2f}%)")
print()

print("üîç –ò–ù–¢–ï–†–ü–†–ï–¢–ò–†–£–ï–ú–û–°–¢–¨:")
print(f"   ‚Ä¢ Feature Importance: ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω")
print(f"   ‚Ä¢ SHAP Values:        {'‚úÖ –í—ã—á–∏—Å–ª–µ–Ω—ã' if 'shap' in dir() else '‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç pip install shap'}")
print(f"   ‚Ä¢ –¢–æ–ø-3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:    {importance_df.iloc[0]['feature']}")
print(f"                         {importance_df.iloc[1]['feature']}")
print(f"                         {importance_df.iloc[2]['feature']}")
print()

print("üìÅ –°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
print(f"   1. model_catboost_iter3.cbm               - –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
print(f"   2. predictions_catboost_iter3.csv         - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test set")
print(f"   3. catboost_iter3_summary.csv             - –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")
print(f"   4. catboost_feature_importance.csv        - Feature importance")
print(f"   5. catboost_interpretation.png            - Feature importance + ROC curve")
print(f"   6. catboost_predictions_analysis.png      - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
if 'shap' in dir():
    print(f"   7. catboost_shap_summary.png              - SHAP values summary")
    print(f"   8. catboost_shap_importance.csv           - SHAP-based importance")
print()

print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
print()

if test_auc >= 0.82:
    print("   ‚úÖ –û–¢–õ–ò–ß–ù–û! Test AUC >= 0.82 –¥–æ—Å—Ç–∏–≥–Ω—É—Ç!")
    print()
    print("   –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π:")
    print("   1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –º–æ–¥–µ–ª—å (—Ö–æ—Ä–æ—à–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å + –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)")
    print("   2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å ensemble —Å XGBoost –¥–ª—è –µ—â–µ –±–æ–ª—å—à–µ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è")
    print("   3. –ü—Ä–∏–º–µ–Ω–∏—Ç—å threshold optimization –¥–ª—è business metrics")
elif test_auc >= 0.81:
    print("   ‚úÖ –•–û–†–û–®–û! Test AUC >= 0.81")
    print()
    print("   –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 0.82+, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:")
    print("   1. Approach #1: LightGBM + ADASYN + Optuna (–æ–∂–∏–¥–∞–µ—Ç—Å—è 0.825-0.84)")
    print("   2. Ensemble: CatBoost + XGBoost stacking")
else:
    print("   ‚ö†Ô∏è  CatBoost –ø–æ–∫–∞–∑–∞–ª —Å–∫—Ä–æ–º–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")
    print()
    print("   –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("   1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: Approach #1 (LightGBM + ADASYN + Optuna)")
    print("   2. Approach #2: Ensemble Stacking")
    print("   3. Hyperparameter tuning —Å Optuna")

print()
print("="*100)
print("‚úÖ –ò–¢–ï–†–ê–¶–ò–Ø 3 –ó–ê–í–ï–†–®–ï–ù–ê!")
print("="*100)
