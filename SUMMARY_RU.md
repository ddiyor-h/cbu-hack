# Подготовка данных для обучения модели - Сводка

**Дата:** 2025-11-15
**Проект:** Прогнозирование кредитных дефолтов
**Целевая метрика:** AUC (Area Under ROC Curve)
**Статус:** ✓ Готово к обучению модели

---

## Что было сделано

Данные успешно подготовлены для обучения моделей машинного обучения. Выполнены все необходимые этапы предобработки, инженерии признаков, кодирования и масштабирования.

---

## Созданные файлы

### Данные для обучения

| Файл | Размер | Описание |
|------|--------|----------|
| **X_train.parquet** | 13 MB | Обучающие признаки (72,000 × 108), немасштабированные |
| **X_test.parquet** | 3.4 MB | Тестовые признаки (17,999 × 108), немасштабированные |
| **X_train_scaled.parquet** | 15 MB | Обучающие признаки (72,000 × 108), масштабированные |
| **X_test_scaled.parquet** | 3.9 MB | Тестовые признаки (17,999 × 108), масштабированные |
| **y_train.parquet** | 1.3 KB | Целевая переменная для обучения (72,000 записей) |
| **y_test.parquet** | 1.3 KB | Целевая переменная для теста (17,999 записей) |

### Метаданные и документация

| Файл | Размер | Описание |
|------|--------|----------|
| **feature_names.txt** | 2.3 KB | Список всех 107 итоговых признаков |
| **preprocessing_metadata.json** | 9.1 MB | Полные метаданные предобработки |
| **class_balance_info.json** | 323 B | Информация о балансе классов и рекомендуемые веса |
| **TRAINING_DATA_PREP_RU.md** | 18 KB | Полная документация всех трансформаций |
| **train_model.py** | 14 KB | Скрипт для обучения моделей |

---

## Характеристики подготовленных данных

### Размеры датасетов

```
Исходный датасет:    89,999 строк × 62 столбца
После инженерии:     89,999 строк × 77 столбцов
После кодирования:   89,999 строк × 108 столбцов

Обучающая выборка:   72,000 строк (80%)
Тестовая выборка:    17,999 строк (20%)
```

### Баланс классов

```
Общее количество дефолтов:    4,594 (5.10%)
Дефолты в обучающей выборке:  3,676 (5.11%)
Дефолты в тестовой выборке:     918 (5.10%)

Соотношение классов: 1:18.6 (не-дефолт:дефолт)
```

**Рекомендуемые веса классов:**
- Класс 0 (нет дефолта): 0.5269
- Класс 1 (дефолт): 9.7953

---

## Инженерия признаков

Создано **16 новых признаков**:

### Финансовые коэффициенты (7)
1. `total_debt_to_income` - Общий долг к доходу
2. `revolving_to_income` - Возобновляемый баланс к доходу
3. `payment_burden` - Нагрузка по платежам
4. `debt_service_coverage` - Покрытие долга
5. `income_vs_regional` - Доход относительно региональной медианы
6. `income_per_dependent` - Доход на иждивенца
7. `combined_risk_score` - Комбинированный показатель риска

### Поведенческие метрики (3)
8. `logins_per_year` - Активность входов в систему
9. `service_calls_per_year` - Обращения в службу поддержки
10. `account_age_years` - Возраст аккаунта

### Кредитные показатели (2)
11. `available_credit_after_loan` - Доступный кредит после займа
12. `credit_capacity` - Общая кредитная емкость

### Категориальные бины (4)
13. `credit_util_category` - Категория использования кредита (низкое/среднее/высокое)
14. `age_group` - Возрастная группа (18-25, 26-35, 36-45, 46-55, 55+)
15. `employment_stability` - Стабильность занятости (новая/короткая/средняя/долгая)
16. `application_time_of_day` - Время подачи заявки (ночь/утро/день/вечер)

---

## Кодирование категориальных признаков

### One-Hot Encoding (11 признаков → 42 бинарных переменных)

Применен к признакам с низкой кардинальностью (< 10 уникальных значений):
- preferred_contact (3 значения)
- account_status_code (5 значений)
- employment_type (9 значений)
- education (5 значений)
- marital_status (3 значения)
- origination_channel (4 значения)
- credit_util_category (3 значения)
- age_group (5 значений)
- employment_stability (4 значения)
- application_time_of_day (4 значения)

### Frequency Encoding (7 признаков)

Применен к признакам с высокой кардинальностью (≥ 10 уникальных значений):
- referral_code (7,805 значений)
- credit_usage_amount (82,354 значений)
- total_monthly_debt_payment (85,634 значений)
- monthly_free_cash_flow (88,109 значений)
- loan_type (12 значений)
- marketing_campaign (26 значений)
- state (20 значений)

---

## Масштабирование

Применена **стандартизация (StandardScaler)**:
- Формула: (x - mean) / std
- Обучение: только на тренировочных данных
- Применение: к обеим выборкам

**Две версии данных:**
1. **Немасштабированная** - для древовидных моделей (Random Forest, XGBoost, LightGBM, CatBoost)
2. **Масштабированная** - для линейных моделей (Logistic Regression) и нейронных сетей

---

## Качество подготовки данных

### Проверки качества
- ✓ Нет пропущенных значений (0 missing values)
- ✓ Все категориальные признаки закодированы
- ✓ Баланс классов сохранен в train/test (5.11% vs 5.10%)
- ✓ Стратифицированное разделение выполнено
- ✓ Кодировщики обучены только на train (нет утечки данных)
- ✓ Масштабирование на основе только train данных
- ✓ Random seed установлен (42) для воспроизводимости
- ✓ Все преобразования документированы

---

## Следующие шаги

### 1. Обучение базовых моделей

Запустите скрипт обучения:
```bash
python3 /home/dr/cbu/train_model.py
```

**Примечание:** Для запуска скрипта необходимо установить хотя бы одну ML библиотеку:
```bash
# Установите виртуальное окружение (если требуется)
python3 -m venv venv
source venv/bin/activate

# Установите необходимые библиотеки
pip install scikit-learn xgboost lightgbm
```

### 2. Рекомендуемые модели для начала

**Для древовидных моделей** (используйте X_train.parquet, X_test.parquet):
- Random Forest
- XGBoost
- LightGBM
- CatBoost

**Для линейных моделей** (используйте X_train_scaled.parquet, X_test_scaled.parquet):
- Logistic Regression
- Ridge/Lasso Regression

### 3. Работа с дисбалансом классов

Обязательно используйте один из методов:
- **Взвешивание классов:** `class_weight='balanced'` или используйте рекомендуемые веса из `class_balance_info.json`
- **SMOTE:** Синтетическая генерация примеров класса меньшинства
- **Оптимизация порога:** Настройка порога классификации на основе ROC-кривой

### 4. Оценка моделей

**Основная метрика:** AUC (Area Under ROC Curve)

**Дополнительные метрики:**
- Precision (точность)
- Recall (полнота)
- F1-Score
- PR-AUC (Precision-Recall AUC)

### 5. Кросс-валидация

Используйте стратифицированную k-fold кросс-валидацию:
```python
from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(
    model,
    X_train,
    y_train,
    cv=5,
    scoring='roc_auc'
)
```

---

## Пример кода для загрузки данных

```python
import pandas as pd
import json

# Загрузка данных для древовидных моделей
X_train = pd.read_parquet('/home/dr/cbu/X_train.parquet')
X_test = pd.read_parquet('/home/dr/cbu/X_test.parquet')

# Загрузка данных для линейных моделей
X_train_scaled = pd.read_parquet('/home/dr/cbu/X_train_scaled.parquet')
X_test_scaled = pd.read_parquet('/home/dr/cbu/X_test_scaled.parquet')

# Загрузка целевой переменной
y_train = pd.read_parquet('/home/dr/cbu/y_train.parquet')['default']
y_test = pd.read_parquet('/home/dr/cbu/y_test.parquet')['default']

# Загрузка метаданных
with open('/home/dr/cbu/class_balance_info.json', 'r') as f:
    class_info = json.load(f)

# Получение рекомендуемых весов классов
class_weights = class_info['recommended_class_weights']
print(f"Рекомендуемые веса: {class_weights}")

# Вывод информации
print(f"Размер обучающей выборки: {X_train.shape}")
print(f"Размер тестовой выборки: {X_test.shape}")
print(f"Процент дефолтов (train): {y_train.mean():.4f}")
print(f"Процент дефолтов (test): {y_test.mean():.4f}")
```

---

## Рекомендации по улучшению

1. **Настройка гиперпараметров**
   - GridSearchCV или RandomizedSearchCV
   - Оптимизация по метрике AUC
   - Кросс-валидация для надежной оценки

2. **Анализ важности признаков**
   - Feature importances для древовидных моделей
   - SHAP values для интерпретации
   - Удаление неинформативных признаков

3. **Ансамблирование**
   - Voting Classifier
   - Stacking
   - Blending

4. **Обработка дисбаланса**
   - Эксперименты с SMOTE
   - Различные веса классов
   - Оптимизация порога классификации

5. **Дополнительная инженерия**
   - Полиномиальные признаки
   - Взаимодействия между признаками
   - Domain-specific трансформации

---

## Структура проекта

```
/home/dr/cbu/
├── final_dataset_imputed.parquet       # Исходный очищенный датасет
├── X_train.parquet                     # Обучающие признаки (немасштабированные)
├── X_test.parquet                      # Тестовые признаки (немасштабированные)
├── X_train_scaled.parquet              # Обучающие признаки (масштабированные)
├── X_test_scaled.parquet               # Тестовые признаки (масштабированные)
├── y_train.parquet                     # Целевая переменная (обучение)
├── y_test.parquet                      # Целевая переменная (тест)
├── feature_names.txt                   # Список всех признаков
├── preprocessing_metadata.json         # Метаданные предобработки
├── class_balance_info.json             # Информация о балансе классов
├── TRAINING_DATA_PREP_RU.md            # Полная документация (этот файл)
├── SUMMARY_RU.md                       # Краткая сводка
└── train_model.py                      # Скрипт для обучения моделей
```

---

## Контрольный список перед обучением

- [x] Данные загружены и проверены
- [x] Пропущенные значения отсутствуют
- [x] Инженерия признаков выполнена
- [x] Категориальные признаки закодированы
- [x] Train/test разделение выполнено со стратификацией
- [x] Масштабирование применено (для линейных моделей)
- [x] Веса классов рассчитаны
- [x] Метаданные сохранены
- [x] Документация создана
- [ ] ML библиотеки установлены (scikit-learn, xgboost и т.д.)
- [ ] Начато обучение базовых моделей
- [ ] Выполнена оценка по метрике AUC
- [ ] Проведена кросс-валидация

---

## Заключение

**Статус:** ✓ Данные полностью подготовлены для обучения моделей

Все необходимые трансформации выполнены. Датасет готов к обучению моделей машинного обучения для прогнозирования кредитных дефолтов.

Следующий шаг - установить ML библиотеки и запустить обучение базовых моделей с помощью скрипта `train_model.py`.

**Ожидаемый результат:** AUC > 0.70 на тестовой выборке с базовыми моделями, возможно улучшение до AUC > 0.80 после настройки гиперпараметров и оптимизации.

---

**Дата подготовки:** 2025-11-15
**Подготовлено:** Data Science Team
**Версия:** 1.0
