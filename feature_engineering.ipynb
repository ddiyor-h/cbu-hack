{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering for Credit Default Prediction\n",
    "## Goal: Improve AUC from 0.7889 to > 0.80\n",
    "\n",
    "### Strategy:\n",
    "1. Interaction features from identified candidates\n",
    "2. Polynomial features for top predictors\n",
    "3. Binning for high-skew features\n",
    "4. Sparse feature indicators\n",
    "5. Domain-specific credit risk features\n",
    "6. Ratio and aggregation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Loading data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_parquet('/home/dr/cbu/X_train.parquet')\n",
    "X_test = pd.read_parquet('/home/dr/cbu/X_test.parquet')\n",
    "y_train = pd.read_parquet('/home/dr/cbu/y_train.parquet').values.ravel()\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Target: {len(y_train)} samples, {y_train.sum()} defaults ({y_train.mean():.2%})\")\n",
    "\n",
    "original_features = X_train.columns.tolist()\n",
    "original_count = len(original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis results\n",
    "numeric_stats = pd.read_csv('/home/dr/cbu/numeric_features_statistics.csv')\n",
    "class_separation = pd.read_csv('/home/dr/cbu/class_separation_analysis.csv')\n",
    "interactions = pd.read_csv('/home/dr/cbu/interaction_candidates.csv')\n",
    "\n",
    "print(\"Analysis files loaded successfully\")\n",
    "print(f\"\\nTop 10 features by KS-statistic:\")\n",
    "print(class_separation.nlargest(10, 'ks_statistic')[['feature', 'ks_statistic', 'median_difference_pct']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating interaction features...\")\n",
    "\n",
    "# Top interaction candidates based on correlation analysis\n",
    "interaction_pairs = [\n",
    "    ('debt_service_ratio', 'payment_to_income_ratio'),\n",
    "    ('debt_service_ratio', 'payment_burden'),\n",
    "    ('payment_to_income_ratio', 'total_debt_to_income'),\n",
    "    ('annual_income', 'age'),\n",
    "    ('credit_score', 'debt_to_income_ratio'),\n",
    "    ('credit_score', 'annual_income'),\n",
    "    ('income_vs_regional', 'debt_service_ratio'),\n",
    "    ('age', 'employment_length'),\n",
    "    ('num_delinquencies_2yrs', 'credit_score'),\n",
    "    ('credit_utilization', 'revolving_balance'),\n",
    "    ('debt_to_income_ratio', 'credit_utilization'),\n",
    "    ('monthly_income', 'existing_monthly_debt'),\n",
    "    ('total_debt_amount', 'annual_income'),\n",
    "    ('available_credit', 'credit_utilization')\n",
    "]\n",
    "\n",
    "interaction_count = 0\n",
    "for feat1, feat2 in interaction_pairs:\n",
    "    if feat1 in X_train.columns and feat2 in X_train.columns:\n",
    "        # Multiplicative interaction\n",
    "        interaction_name = f\"{feat1}_X_{feat2}\"\n",
    "        X_train[interaction_name] = X_train[feat1] * X_train[feat2]\n",
    "        X_test[interaction_name] = X_test[feat1] * X_test[feat2]\n",
    "        interaction_count += 1\n",
    "        \n",
    "        # Ratio interaction (safe division)\n",
    "        if not (X_train[feat2] == 0).any():\n",
    "            ratio_name = f\"{feat1}_div_{feat2}\"\n",
    "            X_train[ratio_name] = X_train[feat1] / (X_train[feat2] + 1e-10)\n",
    "            X_test[ratio_name] = X_test[feat1] / (X_test[feat2] + 1e-10)\n",
    "            interaction_count += 1\n",
    "\n",
    "print(f\"Created {interaction_count} interaction features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial Features for Top Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating polynomial features...\")\n",
    "\n",
    "# Top 5 predictors\n",
    "top_features = class_separation.nlargest(5, 'ks_statistic')['feature'].tolist()\n",
    "top_features = [f for f in top_features if f in X_train.columns]\n",
    "\n",
    "poly_count = 0\n",
    "for feature in top_features:\n",
    "    # Square term\n",
    "    X_train[f\"{feature}_squared\"] = X_train[feature] ** 2\n",
    "    X_test[f\"{feature}_squared\"] = X_test[feature] ** 2\n",
    "    poly_count += 1\n",
    "    \n",
    "    # Cube term (only for features with reasonable range)\n",
    "    if X_train[feature].abs().max() < 100:\n",
    "        X_train[f\"{feature}_cubed\"] = X_train[feature] ** 3\n",
    "        X_test[f\"{feature}_cubed\"] = X_test[feature] ** 3\n",
    "        poly_count += 1\n",
    "    \n",
    "    # Square root (for non-negative features)\n",
    "    if (X_train[feature] >= 0).all():\n",
    "        X_train[f\"{feature}_sqrt\"] = np.sqrt(X_train[feature])\n",
    "        X_test[f\"{feature}_sqrt\"] = np.sqrt(X_test[feature])\n",
    "        poly_count += 1\n",
    "    \n",
    "    # Log transformation (for positive features)\n",
    "    if (X_train[feature] > 0).all():\n",
    "        X_train[f\"{feature}_log\"] = np.log1p(X_train[feature])\n",
    "        X_test[f\"{feature}_log\"] = np.log1p(X_test[feature])\n",
    "        poly_count += 1\n",
    "\n",
    "print(f\"Created {poly_count} polynomial features for {len(top_features)} top predictors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binned Features for High-Skew Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating binned features...\")\n",
    "\n",
    "# High skew features\n",
    "high_skew = numeric_stats[numeric_stats['skewness'].abs() > 3]['feature'].tolist()\n",
    "high_skew = [f for f in high_skew if f in X_train.columns][:10]\n",
    "\n",
    "binned_count = 0\n",
    "for feature in high_skew:\n",
    "    try:\n",
    "        kbd = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "        \n",
    "        binned_train = kbd.fit_transform(X_train[[feature]])\n",
    "        binned_test = kbd.transform(X_test[[feature]])\n",
    "        \n",
    "        X_train[f\"{feature}_binned\"] = binned_train\n",
    "        X_test[f\"{feature}_binned\"] = binned_test\n",
    "        binned_count += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Created {binned_count} binned features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sparse Feature Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating sparse feature indicators...\")\n",
    "\n",
    "# Sparse features (>50% zeros)\n",
    "sparse_features = numeric_stats[numeric_stats['zero_percentage'] > 50]['feature'].tolist()\n",
    "sparse_features = [f for f in sparse_features if f in X_train.columns][:20]\n",
    "\n",
    "sparse_count = 0\n",
    "for feature in sparse_features:\n",
    "    # Binary indicator: has non-zero value\n",
    "    X_train[f\"{feature}_has_value\"] = (X_train[feature] != 0).astype(int)\n",
    "    X_test[f\"{feature}_has_value\"] = (X_test[feature] != 0).astype(int)\n",
    "    sparse_count += 1\n",
    "    \n",
    "    # For very sparse features, create magnitude indicator\n",
    "    zero_pct = numeric_stats[numeric_stats['feature'] == feature]['zero_percentage'].values[0]\n",
    "    if zero_pct > 80:\n",
    "        non_zero = X_train[feature][X_train[feature] != 0]\n",
    "        if len(non_zero) > 10:\n",
    "            q1, q3 = non_zero.quantile([0.25, 0.75])\n",
    "            X_train[f\"{feature}_magnitude\"] = pd.cut(\n",
    "                X_train[feature],\n",
    "                bins=[-np.inf, 0, q1, q3, np.inf],\n",
    "                labels=[0, 1, 2, 3]\n",
    "            ).astype(float)\n",
    "            X_test[f\"{feature}_magnitude\"] = pd.cut(\n",
    "                X_test[feature],\n",
    "                bins=[-np.inf, 0, q1, q3, np.inf],\n",
    "                labels=[0, 1, 2, 3]\n",
    "            ).astype(float)\n",
    "            sparse_count += 1\n",
    "\n",
    "print(f\"Created {sparse_count} sparse feature indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Domain-Specific Credit Risk Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating domain-specific features...\")\n",
    "\n",
    "domain_count = 0\n",
    "\n",
    "# 1. Debt burden score\n",
    "if all(f in X_train.columns for f in ['annual_income', 'total_debt_amount', 'credit_score']):\n",
    "    X_train['debt_burden_score'] = (\n",
    "        X_train['total_debt_amount'] / (X_train['annual_income'] + 1) *\n",
    "        (1000 - X_train['credit_score']) / 1000\n",
    "    )\n",
    "    X_test['debt_burden_score'] = (\n",
    "        X_test['total_debt_amount'] / (X_test['annual_income'] + 1) *\n",
    "        (1000 - X_test['credit_score']) / 1000\n",
    "    )\n",
    "    domain_count += 1\n",
    "\n",
    "# 2. Credit utilization categories\n",
    "if 'credit_utilization' in X_train.columns:\n",
    "    X_train['credit_util_category'] = pd.cut(\n",
    "        X_train['credit_utilization'],\n",
    "        bins=[0, 0.3, 0.5, 0.7, 1.0],\n",
    "        labels=[1, 2, 3, 4]\n",
    "    ).astype(float).fillna(0)\n",
    "    X_test['credit_util_category'] = pd.cut(\n",
    "        X_test['credit_utilization'],\n",
    "        bins=[0, 0.3, 0.5, 0.7, 1.0],\n",
    "        labels=[1, 2, 3, 4]\n",
    "    ).astype(float).fillna(0)\n",
    "    domain_count += 1\n",
    "\n",
    "# 3. Income vs expected by age\n",
    "if all(f in X_train.columns for f in ['age', 'annual_income']):\n",
    "    expected_income_train = 20000 + (X_train['age'] - 18) * 2000\n",
    "    expected_income_test = 20000 + (X_test['age'] - 18) * 2000\n",
    "    \n",
    "    X_train['income_vs_age_expected'] = X_train['annual_income'] / expected_income_train\n",
    "    X_test['income_vs_age_expected'] = X_test['annual_income'] / expected_income_test\n",
    "    domain_count += 1\n",
    "\n",
    "# 4. Payment capacity\n",
    "if all(f in X_train.columns for f in ['monthly_free_cash_flow', 'monthly_payment']):\n",
    "    X_train['payment_capacity'] = X_train['monthly_free_cash_flow'] / (X_train['monthly_payment'] + 100)\n",
    "    X_test['payment_capacity'] = X_test['monthly_free_cash_flow'] / (X_test['monthly_payment'] + 100)\n",
    "    domain_count += 1\n",
    "\n",
    "# 5. Combined risk score\n",
    "risk_factors = ['num_delinquencies_2yrs', 'debt_service_ratio', 'payment_to_income_ratio']\n",
    "available_risk = [f for f in risk_factors if f in X_train.columns]\n",
    "\n",
    "if available_risk:\n",
    "    risk_scores_train = pd.DataFrame()\n",
    "    risk_scores_test = pd.DataFrame()\n",
    "    \n",
    "    for factor in available_risk:\n",
    "        min_val = X_train[factor].min()\n",
    "        max_val = X_train[factor].max()\n",
    "        risk_scores_train[factor] = (X_train[factor] - min_val) / (max_val - min_val + 1e-10)\n",
    "        risk_scores_test[factor] = (X_test[factor] - min_val) / (max_val - min_val + 1e-10)\n",
    "    \n",
    "    X_train['combined_risk_score'] = risk_scores_train.mean(axis=1)\n",
    "    X_test['combined_risk_score'] = risk_scores_test.mean(axis=1)\n",
    "    domain_count += 1\n",
    "\n",
    "# 6. Financial stress indicator\n",
    "if all(f in X_train.columns for f in ['debt_to_income_ratio', 'credit_utilization']):\n",
    "    X_train['financial_stress'] = X_train['debt_to_income_ratio'] * X_train['credit_utilization']\n",
    "    X_test['financial_stress'] = X_test['debt_to_income_ratio'] * X_test['credit_utilization']\n",
    "    domain_count += 1\n",
    "\n",
    "# 7. Credit score risk bucket\n",
    "if 'credit_score' in X_train.columns:\n",
    "    X_train['credit_score_bucket'] = pd.cut(\n",
    "        X_train['credit_score'],\n",
    "        bins=[0, 580, 670, 740, 800, 1000],\n",
    "        labels=[5, 4, 3, 2, 1]  # Higher number = higher risk\n",
    "    ).astype(float).fillna(5)\n",
    "    X_test['credit_score_bucket'] = pd.cut(\n",
    "        X_test['credit_score'],\n",
    "        bins=[0, 580, 670, 740, 800, 1000],\n",
    "        labels=[5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(5)\n",
    "    domain_count += 1\n",
    "\n",
    "print(f\"Created {domain_count} domain-specific features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating additional ratio features...\")\n",
    "\n",
    "ratio_pairs = [\n",
    "    ('revolving_balance', 'available_credit'),\n",
    "    ('monthly_payment', 'monthly_income'),\n",
    "    ('existing_monthly_debt', 'monthly_income'),\n",
    "    ('total_debt_amount', 'annual_income'),\n",
    "    ('num_customer_service_calls', 'account_tenure_years'),\n",
    "    ('num_login_sessions', 'account_tenure_years')\n",
    "]\n",
    "\n",
    "ratio_count = 0\n",
    "for numerator, denominator in ratio_pairs:\n",
    "    if numerator in X_train.columns and denominator in X_train.columns:\n",
    "        ratio_name = f\"ratio_{numerator}_to_{denominator}\"\n",
    "        X_train[ratio_name] = X_train[numerator] / (X_train[denominator] + 1e-10)\n",
    "        X_test[ratio_name] = X_test[numerator] / (X_test[denominator] + 1e-10)\n",
    "        \n",
    "        # Cap extreme values\n",
    "        cap_value = X_train[ratio_name].quantile(0.99)\n",
    "        X_train[ratio_name] = X_train[ratio_name].clip(upper=cap_value)\n",
    "        X_test[ratio_name] = X_test[ratio_name].clip(upper=cap_value)\n",
    "        ratio_count += 1\n",
    "\n",
    "print(f\"Created {ratio_count} additional ratio features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating aggregation features...\")\n",
    "\n",
    "agg_count = 0\n",
    "\n",
    "# Debt-related features\n",
    "debt_features = [f for f in X_train.columns if 'debt' in f.lower() and f in original_features]\n",
    "if len(debt_features) > 1:\n",
    "    X_train['debt_features_mean'] = X_train[debt_features].mean(axis=1)\n",
    "    X_train['debt_features_std'] = X_train[debt_features].std(axis=1)\n",
    "    X_train['debt_features_max'] = X_train[debt_features].max(axis=1)\n",
    "    \n",
    "    X_test['debt_features_mean'] = X_test[debt_features].mean(axis=1)\n",
    "    X_test['debt_features_std'] = X_test[debt_features].std(axis=1)\n",
    "    X_test['debt_features_max'] = X_test[debt_features].max(axis=1)\n",
    "    agg_count += 3\n",
    "\n",
    "# Payment-related features\n",
    "payment_features = [f for f in X_train.columns if 'payment' in f.lower() and f in original_features]\n",
    "if len(payment_features) > 1:\n",
    "    X_train['payment_features_mean'] = X_train[payment_features].mean(axis=1)\n",
    "    X_train['payment_features_sum'] = X_train[payment_features].sum(axis=1)\n",
    "    \n",
    "    X_test['payment_features_mean'] = X_test[payment_features].mean(axis=1)\n",
    "    X_test['payment_features_sum'] = X_test[payment_features].sum(axis=1)\n",
    "    agg_count += 2\n",
    "\n",
    "print(f\"Created {agg_count} aggregation features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValidating features...\")\n",
    "\n",
    "# Replace infinite values\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill NaN values\n",
    "nan_cols_train = X_train.columns[X_train.isna().any()].tolist()\n",
    "nan_cols_test = X_test.columns[X_test.isna().any()].tolist()\n",
    "\n",
    "if nan_cols_train or nan_cols_test:\n",
    "    print(f\"Filling NaN values in {len(set(nan_cols_train + nan_cols_test))} features\")\n",
    "    for col in set(nan_cols_train + nan_cols_test):\n",
    "        if col in X_train.columns:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col] = X_train[col].fillna(median_val)\n",
    "            X_test[col] = X_test[col].fillna(median_val)\n",
    "\n",
    "# Remove low variance features\n",
    "low_var_features = numeric_stats[numeric_stats['std'] < 0.01]['feature'].tolist()\n",
    "low_var_to_remove = [f for f in low_var_features if f in X_train.columns]\n",
    "\n",
    "if low_var_to_remove:\n",
    "    X_train = X_train.drop(columns=low_var_to_remove)\n",
    "    X_test = X_test.drop(columns=low_var_to_remove)\n",
    "    print(f\"Removed {len(low_var_to_remove)} low-variance features\")\n",
    "\n",
    "print(f\"\\nFinal shape - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"New features created: {X_train.shape[1] - original_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAssessing feature quality...\")\n",
    "\n",
    "# Calculate correlations with target for new features\n",
    "new_features = [f for f in X_train.columns if f not in original_features]\n",
    "correlations = {}\n",
    "\n",
    "for col in new_features[:100]:  # Check first 100 new features\n",
    "    corr = np.abs(np.corrcoef(X_train[col], y_train)[0, 1])\n",
    "    if not np.isnan(corr):\n",
    "        correlations[col] = corr\n",
    "\n",
    "# Sort by correlation\n",
    "top_new_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "print(\"\\nTop 20 new features by target correlation:\")\n",
    "for i, (feat, corr) in enumerate(top_new_features, 1):\n",
    "    print(f\"{i:2d}. {feat[:60]:60s} {corr:.4f}\")\n",
    "\n",
    "# Save correlation results\n",
    "corr_df = pd.DataFrame(list(correlations.items()), columns=['feature', 'abs_correlation'])\n",
    "corr_df = corr_df.sort_values('abs_correlation', ascending=False)\n",
    "corr_df.to_csv('/home/dr/cbu/new_features_correlations.csv', index=False)\n",
    "print(\"\\nSaved correlation analysis to new_features_correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSaving engineered features...\")\n",
    "\n",
    "X_train.to_parquet('/home/dr/cbu/X_train_engineered.parquet', engine='pyarrow', compression='snappy')\n",
    "X_test.to_parquet('/home/dr/cbu/X_test_engineered.parquet', engine='pyarrow', compression='snappy')\n",
    "\n",
    "print(f\"Saved X_train_engineered.parquet: {X_train.shape}\")\n",
    "print(f\"Saved X_test_engineered.parquet: {X_test.shape}\")\n",
    "print(\"\\nFeature engineering completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal features: {original_count}\")\n",
    "print(f\"Final features: {X_train.shape[1]}\")\n",
    "print(f\"New features: {X_train.shape[1] - original_count}\")\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"\\nDefault rate: {y_train.mean():.2%}\")\n",
    "print(f\"Class imbalance ratio: 1:{int(1/y_train.mean())}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
