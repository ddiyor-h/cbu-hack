# Результаты первой итерации обучения модели XGBoost

**Дата:** 2025-11-15
**Модель:** XGBoost v3.1.1
**Время обучения:** 12:37 - 12:42 (5 минут 27 секунд)

---

## Ответы на вопросы

### Вопрос 1: Стоит ли использовать XGBoost для первой итерации?

**Ответ: ДА, абсолютно правильный выбор.**

**Обоснование:**

1. **Оптимизация целевой метрики (AUC)**
   - XGBoost напрямую оптимизирует AUC через параметр `eval_metric='auc'`
   - Это критически важно, так как проект оценивается именно по метрике AUC
   - Результат подтвердил эффективность: **Test AUC = 0.7900**

2. **Обработка дисбаланса классов**
   - Встроенная поддержка через `scale_pos_weight=18.59`
   - Автоматическая балансировка для дисбаланса 1:18.6 (5.1% дефолтов)
   - Хорошая recall на минорном классе: **65%** (595 из 918 дефолтов обнаружено)

3. **Устойчивость к переобучению**
   - Регуляризация (L1/L2) встроена по умолчанию
   - Early stopping остановил обучение на итерации 25 из 1000
   - Умеренный overfit gap: **0.0746** (train_auc - test_auc)

4. **Обработка большого числа признаков**
   - 108 признаков без предварительной фильтрации
   - XGBoost автоматически определил важные признаки
   - 5 признаков получили нулевую важность (автоматически проигнорированы)

5. **Надежный baseline для сравнения**
   - Стабильная кросс-валидация: **0.7973 ± 0.0077 AUC**
   - Низкая вариативность между фолдами (min=0.7908, max=0.8098)
   - Хорошая обобщающая способность (test AUC близок к CV AUC)

**Вывод:** XGBoost - оптимальный выбор для первой итерации. Модель показала стабильные результаты, эффективно обработала дисбаланс классов и автоматически выявила важные признаки.

---

### Вопрос 2: Использовать ВСЕ 108 колонок как стартовую точку?

**Ответ: ДА, это правильная стратегия.**

**Обоснование по результатам обучения:**

1. **Нет потери информации**
   - Все потенциально значимые признаки учтены
   - Top 20 признаков покрывают только **40.7%** важности - остальные 88 признаков вносят **59.3%** вклада
   - Это значит, что отбрасывание признаков на этапе 1 могло бы ухудшить модель

2. **Автоматическая фильтрация XGBoost**
   - Только **5 признаков из 108** получили нулевую важность (4.6%)
   - Еще **5 признаков** с почти нулевой важностью (<0.001)
   - **98 признаков из 108** (90.7%) активно используются моделью

3. **Нет проблем с производительностью**
   - Обучение на 72,000 строках × 108 признаках заняло всего **44 секунды**
   - Кросс-валидация (5 фолдов): **278 секунд** (4.6 минуты)
   - Время приемлемо для экспериментирования

4. **Контролируемое переобучение**
   - Overfit gap = **0.0746** (умеренный, не критичный)
   - Early stopping сработал на итерации 25 (из 1000 возможных)
   - Модель не переобучилась даже со всеми 108 признаками

5. **Ценная информация для следующих итераций**
   - Теперь точно известно, какие признаки важны (см. таблицу ниже)
   - Можно обоснованно удалить 5 признаков с нулевой важностью
   - Видно, какие признаки стоит инженерить дальше

**Вывод:** Использование всех 108 признаков было правильным решением. Это дало полную картину важности признаков без предвзятости, не привело к критическому переобучению и показало хорошие результаты.

---

## Результаты обучения

### Основные метрики производительности

| Метрика | Значение | Комментарий |
|---------|----------|-------------|
| **Test AUC** | **0.7900** | Основная метрика качества |
| **CV AUC (mean)** | **0.7973 ± 0.0077** | Стабильная кросс-валидация |
| **Train AUC** | 0.8647 | Хорошо обучается на обучающей выборке |
| **Overfit Gap** | 0.0746 | Умеренное переобучение |
| **Test Accuracy** | 0.78 | 78% правильных предсказаний |

### Детализация по метрикам

**Кросс-валидация (5-fold Stratified):**
```
Fold 1: AUC = 0.8098 (лучший фолд)
Fold 2: AUC = 0.7920
Fold 3: AUC = 0.7908 (худший фолд)
Fold 4: AUC = 0.7909
Fold 5: AUC = 0.8028
---
Mean:   0.7973 ± 0.0077
Range:  0.7908 - 0.8098 (разброс 0.019)
```

**Вывод:** Низкий разброс (σ=0.0077) указывает на стабильность модели и хорошую обобщающую способность.

### Confusion Matrix (Test Set)

|                  | Predicted: No Default | Predicted: Default |
|------------------|----------------------:|-------------------:|
| **Actual: No Default** | 13,453 (TN) | 3,628 (FP) |
| **Actual: Default**    | 323 (FN)    | 595 (TP)   |

**Интерпретация:**
- **True Positives (595):** 65% дефолтов обнаружено - ХОРОШО для дисбаланса 1:18.6
- **False Negatives (323):** 35% дефолтов пропущено - можно улучшить
- **False Positives (3,628):** 21% ложных тревог среди нормальных кредитов
- **True Negatives (13,453):** 79% нормальных кредитов правильно классифицированы

### Метрики по классам

| Класс | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| **No Default (0)** | 0.98 | 0.79 | 0.87 | 17,081 |
| **Default (1)** | 0.14 | 0.65 | 0.23 | 918 |
| **Weighted Avg** | 0.93 | 0.78 | 0.84 | 17,999 |

**Ключевые наблюдения:**
- **Recall для дефолтов (0.65):** Модель находит 2 из 3 дефолтов - неплохо для первой итерации
- **Precision для дефолтов (0.14):** Из всех предсказанных дефолтов только 14% реальные - есть куда расти
- **Trade-off:** Модель консервативна (много ложных тревог), что приемлемо для кредитного скоринга

---

## Анализ важности признаков

### Top 20 наиболее важных признаков

| Ранг | Признак | Важность | Категория |
|------|---------|----------|-----------|
| 1 | **credit_score** | 0.0516 | Кредитная история |
| 2 | **income_vs_regional** | 0.0411 | Инженерный признак |
| 3 | **monthly_income** | 0.0382 | Доход |
| 4 | **debt_service_coverage** | 0.0294 | Инженерный признак |
| 5 | **annual_income** | 0.0280 | Доход |
| 6 | **age** | 0.0266 | Демография |
| 7 | **payment_burden** | 0.0248 | Инженерный признак |
| 8 | **debt_service_ratio** | 0.0194 | Финансовые коэффициенты |
| 9 | **loan_purpose_Home Purchase** | 0.0169 | Цель кредита |
| 10 | **payment_to_income_ratio** | 0.0153 | Финансовые коэффициенты |
| 11 | **age_group_36-45** | 0.0143 | Демография (категориальная) |
| 12 | **employment_stability_short** | 0.0133 | Стабильность занятости |
| 13 | **age_group_46-55** | 0.0128 | Демография (категориальная) |
| 14 | **total_debt_to_income** | 0.0118 | Финансовые коэффициенты |
| 15 | **num_public_records** | 0.0110 | Кредитная история |
| 16 | **num_delinquencies_2yrs** | 0.0108 | Кредитная история |
| 17 | **employment_type_Part Time** | 0.0107 | Занятость |
| 18 | **num_credit_accounts** | 0.0106 | Кредитная история |
| 19 | **education_Some College** | 0.0103 | Образование |
| 20 | **marital_status_Single** | 0.0103 | Демография |
| **ИТОГО (Top 20)** | | **0.407** | **40.7% важности** |

### Признаки с нулевой или околонулевой важностью

**Нулевая важность (можно удалить):**
1. `preferred_contact_Mail` - метод контакта не влияет на дефолт
2. `credit_util_category_low` - дублирует числовой признак `credit_utilization`
3. `loan_purpose_Revolving Credit` - редкая категория или линейно зависима от других
4. `employment_stability_new` - возможно, мало примеров или дублирует другие признаки
5. `age_group_55+` - возможно, линейно зависим от `age`

**Почти нулевая важность (<0.001, можно рассмотреть удаление):**
- `education_Bachelor` (0.0027)
- `credit_util_category_medium` (0.0035)
- `loan_purpose_Home Improvement` (0.0036)
- `marital_status_Married` (0.0038)
- `account_status_code_ACTIVE` (0.0043)

### Выводы по признакам

**Что работает хорошо:**
1. **Кредитные метрики** (credit_score, num_public_records, num_delinquencies_2yrs) - ожидаемо важны
2. **Инженерные признаки** (income_vs_regional, debt_service_coverage, payment_burden) - TOP-2, TOP-4, TOP-7!
3. **Финансовые коэффициенты** (debt_service_ratio, payment_to_income_ratio, total_debt_to_income)
4. **Доходные метрики** (monthly_income, annual_income)
5. **Демография** (age, age_group категории) - удивительно важна

**Что можно улучшить:**
- 5 признаков с нулевой важностью явно избыточны
- Некоторые категориальные признаки (education, marital_status) имеют низкую важность
- Возможно, есть мультиколлинеарность между `monthly_income` и `annual_income`

---

## Анализ переобучения

### Метрики переобучения

```
Train AUC:     0.8647
Test AUC:      0.7900
Overfit Gap:   0.0746 (8.6% относительно test AUC)
```

### Оценка степени переобучения

**Уровень:** УМЕРЕННЫЙ (приемлемый для первой итерации)

**Анализ:**
- Gap 0.0746 - это ~9% разница относительно test AUC
- Для дерева решений с 108 признаками это нормально
- Early stopping остановил обучение на итерации 25 (из 1000) - защита сработала
- CV AUC (0.7973) **выше** Test AUC (0.7900) - признак хорошей обобщающей способности

**Причины умеренного переобучения:**
1. 108 признаков на 72,000 объектов (соотношение 1:667 - хорошее)
2. Базовые гиперпараметры без агрессивной регуляризации:
   - `max_depth=6` - средняя глубина деревьев
   - `min_child_weight=1` - низкое значение (больше переобучение)
   - `gamma=0` - нет penalty за листья
   - `reg_alpha=0`, `reg_lambda=1` - только L2 регуляризация

**Как контролируется:**
- `subsample=0.8` - 20% данных не используются в каждом дереве
- `colsample_bytree=0.8` - 20% признаков не используются в каждом дереве
- Early stopping - остановка при ухудшении на валидации

**Вывод:** Переобучение под контролем, не критично для первой итерации.

---

## Рекомендации для второй итерации

### 1. Очистка признаков (Feature Pruning)

**Удалить:**
- 5 признаков с нулевой важностью (список выше)
- Потенциально 5 признаков с важностью <0.001

**Ожидаемый эффект:**
- Уменьшение размерности: 108 → 98-103 признака
- Минимальная потеря качества (эти признаки не использовались)
- Ускорение обучения на ~5-10%
- Снижение переобучения

### 2. Тонкая настройка гиперпараметров (Hyperparameter Tuning)

**Приоритетные параметры для оптимизации:**

| Параметр | Текущее | Рекомендуемый диапазон | Эффект |
|----------|---------|------------------------|--------|
| `max_depth` | 6 | [4, 5, 6, 7] | Контроль сложности |
| `min_child_weight` | 1 | [3, 5, 7, 10] | Снизить переобучение |
| `gamma` | 0 | [0, 0.1, 0.2, 0.5] | Penalty за листья |
| `subsample` | 0.8 | [0.7, 0.8, 0.9] | Стохастичность |
| `colsample_bytree` | 0.8 | [0.6, 0.7, 0.8] | Случайные признаки |
| `learning_rate` | 0.1 | [0.05, 0.1] | Размер шага |
| `reg_alpha` | 0 | [0, 0.1, 1] | L1 регуляризация |
| `reg_lambda` | 1 | [1, 2, 5] | L2 регуляризация |

**Стратегия:**
- Использовать RandomizedSearchCV или Optuna для автоматического поиска
- 50-100 комбинаций, 3-fold CV для скорости
- Целевая метрика: максимизация AUC

**Ожидаемый прирост:** +0.01-0.03 AUC (итого 0.80-0.82)

### 3. Threshold Optimization (настройка порога классификации)

**Текущий порог:** 0.5 (по умолчанию)

**Проблема:**
- Precision для дефолтов = 0.14 (только 14% предсказанных дефолтов - реальные)
- Recall для дефолтов = 0.65 (находим 65% дефолтов)

**Решение:**
- Подобрать оптимальный порог для максимизации метрики оценки проекта (AUC)
- Или для бизнес-метрики (например, F1-score для класса дефолта)
- Построить Precision-Recall кривую и выбрать точку

**Инструменты:**
- `sklearn.metrics.precision_recall_curve`
- Выбрать порог, который балансирует precision/recall для класса 1

### 4. Техники работы с дисбалансом

**Текущий подход:**
- `scale_pos_weight=18.59` - работает хорошо (recall=0.65)

**Дополнительные техники для тестирования:**
1. **SMOTE (Synthetic Minority Over-sampling)**
   - Генерировать синтетические примеры дефолтов
   - Может улучшить recall до 0.70-0.75

2. **Threshold Moving**
   - Снизить порог классификации с 0.5 до 0.3-0.4
   - Больше recall, меньше precision

3. **Focal Loss**
   - Использовать кастомную функцию потерь в XGBoost
   - `objective='custom'` с focal loss для фокуса на сложных примерах

### 5. Feature Engineering (второй раунд)

**На основе важности признаков:**

1. **Взаимодействия TOP-признаков:**
   - `credit_score × debt_service_ratio`
   - `income_vs_regional × payment_burden`
   - `age × employment_stability_short`

2. **Полиномиальные признаки для TOP-3:**
   - `credit_score^2`, `sqrt(credit_score)`
   - `log(monthly_income)`, `log(annual_income)`

3. **Агрегаты кредитной истории:**
   - `total_negative_records = num_public_records + num_delinquencies_2yrs`
   - `credit_quality_score = credit_score / (1 + num_public_records)`

4. **Возрастные когорты:**
   - Текущие age_group работают хорошо - возможно, создать более детальные

### 6. Попробовать ансамбль моделей

**Варианты:**
1. **XGBoost + LightGBM** (стекинг)
2. **XGBoost + Logistic Regression** (разные подходы)
3. **Voting Classifier** с несколькими XGBoost моделями (разные random seeds)

**Ожидаемый прирост:** +0.005-0.015 AUC

### 7. Другие алгоритмы для сравнения

**Кандидаты:**
- **LightGBM:** Быстрее XGBoost, может дать +0.01 AUC
- **CatBoost:** Хорош для категориальных признаков, автоматическая обработка
- **Logistic Regression (с регуляризацией):** Baseline для интерпретируемости
- **Random Forest:** Более консервативный, меньше переобучение

---

## Краткое резюме

### Что сделано

1. Обучена модель XGBoost на **всех 108 признаках**
2. Проведена **5-fold кросс-валидация** (стабильные результаты)
3. Достигнут **Test AUC = 0.7900** (хорошая отправная точка)
4. Выявлено **5 бесполезных признаков** (можно удалить)
5. Определены **Top-20 важных признаков** (40.7% важности)
6. Переобучение **под контролем** (gap = 0.0746)

### Ответы на вопросы

**Q1: Использовать XGBoost для первой итерации?**
→ **ДА.** Показал AUC=0.79, стабильную CV, хорошую обработку дисбаланса.

**Q2: Использовать все 108 признаков?**
→ **ДА.** Только 5 признаков оказались бесполезными, остальные 103 вносят вклад. Top-20 покрывают лишь 40.7% важности.

### Следующие шаги (итерация 2)

**Приоритет 1 (быстрый прирост):**
1. Удалить 5 признаков с нулевой важностью
2. Настроить гиперпараметры (RandomizedSearch, 50 комбинаций)
3. Ожидаемый результат: **AUC 0.80-0.82**

**Приоритет 2 (дополнительный прирост):**
4. Feature engineering (взаимодействия TOP-признаков)
5. Threshold optimization для баланса precision/recall
6. Ожидаемый результат: **AUC 0.82-0.84**

**Приоритет 3 (для максимизации):**
7. Попробовать LightGBM и CatBoost
8. Ансамбль моделей (стекинг)
9. Ожидаемый результат: **AUC 0.84+**

### Оценка текущей модели

**Сильные стороны:**
- Стабильная кросс-валидация (σ=0.0077)
- Хороший recall для дефолтов (0.65) при сильном дисбалансе
- Автоматически выявлены важные признаки
- Умеренное переобучение (контролируемое)

**Слабые стороны:**
- Precision для дефолтов низкая (0.14) - много ложных тревог
- Есть небольшой overfit gap (0.0746)
- Базовые гиперпараметры (не оптимизированы)
- 5 бесполезных признаков все еще в модели

### Итоговая оценка первой итерации

**Оценка:** УСПЕШНАЯ ПЕРВАЯ ИТЕРАЦИЯ

- Модель работает (AUC=0.79 - выше случайного уровня 0.5)
- Результаты стабильны и воспроизводимы
- Получена ценная информация о признаках
- Есть четкий план улучшения для итерации 2

**Прогноз финальной модели:** При правильной оптимизации возможен **AUC 0.82-0.85**.

---

## Созданные файлы

1. **`/home/dr/cbu/xgboost_model_v1.json`** - сохраненная модель
2. **`/home/dr/cbu/xgboost_predictions_v1.csv`** - предсказания на тестовой выборке
3. **`/home/dr/cbu/xgboost_metrics_v1.json`** - все метрики в JSON
4. **`/home/dr/cbu/xgboost_feature_importance_v1.csv`** - важность всех 108 признаков
5. **`/home/dr/cbu/xgboost_results_v1.png`** - визуализации (ROC, PR-кривые, важность признаков)
6. **`/home/dr/cbu/train_xgboost_first_iteration.py`** - скрипт обучения (воспроизводимость)
7. **`/home/dr/cbu/FIRST_ITERATION_RESULTS_RU.md`** - этот отчет

---

**Конец отчета**
